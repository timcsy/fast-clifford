# fast-clifford 效能基準測試報告

**測試日期**: 2025-12-07
**測試環境**: macOS Darwin 24.6.0, Apple Silicon (MPS)
**Python**: 3.12.11
**PyTorch**: 2.0+

## 1. 專案概述

fast-clifford 是一個針對 3D 共形幾何代數 (CGA) Cl(4,1) 的高效能程式碼生成器，專為深度學習應用優化。

### 代數規格

| 項目 | 數值 |
|------|------|
| 代數類型 | CGA Cl(4,1) |
| 簽名 | (+,+,+,+,-) |
| Blade 數量 | 32 |
| Motor 分量 | 16 (Grade 0, 2, 4) |
| UPGC Point 分量 | 5 (Grade 1) |

## 2. 計算量優化

### 稀疏性優化

透過利用 UPGC Point 和 Motor 的稀疏結構，三明治積計算量大幅減少：

| 項目 | 數值 |
|------|------|
| 稀疏三明治積乘法 | 800 次 |
| 完整計算乘法 | 2,048 次 |
| **計算量減少** | **60.9%** |

### 實作特點

- **硬編碼運算**：無 Cayley 表查詢，直接展開算術
- **無迴圈**：所有運算完全展開，ONNX 相容
- **JIT 編譯**：使用 `@torch.jit.script` 優化

## 3. 數值精度驗證

| 測試項目 | 誤差 |
|----------|------|
| Identity Motor 變換 | 0.00e+00 |
| 90 度旋轉變換 | 5.96e-08 |

數值精度達到 float32 的機器精度等級。

## 4. 效能基準測試

### 4.1 fast-clifford vs clifford 庫對比

測試內容：三明治積 M × X × M̃

#### CPU 效能對比

| 樣本數 | clifford (ms) | fast-clifford (ms) | 加速倍數 |
|--------|---------------|-------------------|----------|
| 1 | 0.03 | 0.73 | 0.04x |
| 10 | 0.17 | 0.67 | 0.3x |
| 100 | 1.28 | 0.74 | **1.7x** |
| 1,000 | 12.86 | 0.86 | **14.9x** |
| 5,000 | 69.07 | 2.53 | **27.3x** |

#### GPU (MPS) vs CPU (clifford) 對比

| 樣本數 | clifford CPU (ms) | fast-clifford MPS (ms) | 加速倍數 |
|--------|-------------------|------------------------|----------|
| 1,000 | 18.73 | 7.10 | **2.6x** |
| 5,000 | 71.98 | 25.65 | **2.8x** |
| 10,000 | 202.08 | 4.16 | **48.6x** |

### 4.2 吞吐量測試

#### CPU 吞吐量

| Batch Size | Time (ms) | Throughput |
|------------|-----------|------------|
| 1 | 0.604 | 1,657 pts/s |
| 16 | 0.587 | 27,248 pts/s |
| 64 | 0.580 | 110,317 pts/s |
| 256 | 0.591 | 433,485 pts/s |
| 1,024 | 0.733 | **1,396,154 pts/s** |

#### MPS (Apple Silicon) 吞吐量

| Batch Size | Time (ms) | Throughput |
|------------|-----------|------------|
| 1 | 2.486 | 402 pts/s |
| 16 | 1.668 | 9,595 pts/s |
| 64 | 1.802 | 35,518 pts/s |
| 256 | 2.864 | 89,382 pts/s |
| 1,024 | 1.938 | **528,397 pts/s** |

## 5. 精度支援

| 精度類型 | 支援狀態 | 備註 |
|----------|----------|------|
| float32 | ✓ | 預設精度 |
| float16 | ✓ | 內部轉 float32 計算 |
| bfloat16 | ✓ | 內部轉 float32 計算 |

CGACareLayer 自動處理精度轉換：`fp16 輸入 → fp32 計算 → fp16 輸出`

## 6. ONNX 匯出

| 項目 | 結果 |
|------|------|
| ONNX opset | 17 |
| 檔案大小 | 68.4 KB |
| Loop 節點 | 0 ✓ |
| 使用算子 | Add, Concat, Gather, Mul, Neg, Unsqueeze |

所有算子都是 TensorRT 原生支援，可直接部署。

## 7. 測試覆蓋

| 測試類型 | 數量 | 結果 |
|----------|------|------|
| 數值正確性 | 29 | ✓ 全部通過 |
| ONNX 匯出 | 10 | ✓ 全部通過 |
| 跨平台 | 4 | ✓ 3 通過, 1 跳過 (CUDA) |
| 精度測試 | 5 | ✓ 全部通過 |
| **總計** | **48** | **47 通過, 1 跳過** |

## 8. 功能對比總結

| 功能 | clifford | fast-clifford |
|------|----------|---------------|
| 批次處理 | ✗ 需要迴圈 | ✓ 原生支援 |
| GPU 加速 | ✗ | ✓ CUDA/MPS |
| ONNX 匯出 | ✗ | ✓ |
| TensorRT 部署 | ✗ | ✓ |
| PyTorch autograd | ✗ | ✓ |
| 符號計算 | ✓ | ✗ |
| 任意代數支援 | ✓ 通用 | CGA 專用 |

## 9. 使用建議

### 適合使用 fast-clifford 的場景

1. **深度學習訓練**：批次處理效能提升 15-50 倍
2. **即時推論**：可匯出 ONNX 部署到 TensorRT
3. **批量幾何變換**：大批次 (>100) 有顯著優勢
4. **GPU 加速需求**：原生支援 CUDA/MPS

### 適合使用 clifford 庫的場景

1. **研究和原型開發**：符號計算方便
2. **單點計算**：小批次 (<10) 開銷較低
3. **需要任意 Clifford 代數**：fast-clifford 僅支援 CGA Cl(4,1)

## 10. 結論

fast-clifford 在批次處理場景下提供顯著的效能優勢：

- **CPU 大批次**：比 clifford 快 **27 倍**
- **GPU 大批次**：比 clifford 快 **48 倍**
- **吞吐量**：CPU 可達 **140 萬點/秒**，MPS 可達 **53 萬點/秒**
- **計算量**：透過稀疏優化減少 **61%**

這使得 fast-clifford 非常適合用於 CARE Transformer 等需要高效幾何運算的深度學習模型。
