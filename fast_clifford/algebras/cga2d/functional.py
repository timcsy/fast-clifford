"""
CGA2D Cl(3,1) Functional Operations - Auto-generated

DO NOT EDIT MANUALLY - This file is generated by codegen/generate.py

Generated: 2025-12-09 02:13:22
Algebra: cga2d
Signature: (1, 1, 1, -1)
Blade count: 16

All functions are:
- Loop-free (fully expanded arithmetic)
- ONNX-compatible (only Add/Mul/Neg/Sub operations)
- Hard-coded (no Cayley table lookups)
"""

import torch
from torch import Tensor
from typing import Tuple


# =============================================================================
# Constants
# =============================================================================

BLADE_COUNT = 16
EUCLIDEAN_DIM = 2

# Blade indices by grade
GRADE_0_INDICES = (0,)
GRADE_1_INDICES = (1, 2, 3, 4)
GRADE_2_INDICES = (5, 6, 7, 8, 9, 10)
GRADE_3_INDICES = (11, 12, 13, 14)
GRADE_4_INDICES = (15,)

# Sparsity masks
UPGC_POINT_MASK = (1, 2, 3, 4)  # 4 components
EVEN_VERSOR_MASK = (0, 5, 6, 7, 8, 9, 10, 15)  # 8 components

# Reverse signs for all 16 blades
REVERSE_SIGNS = (1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1)

# EvenVersor-specific reverse signs (8 components)
EVEN_VERSOR_REVERSE_SIGNS = (1, -1, -1, -1, -1, -1, -1, 1)

# =============================================================================
# Geometric Product (Full 16x16)
# =============================================================================

@torch.jit.script
def geometric_product_full(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute the full geometric product of two multivectors.

    Args:
        a: Left operand, shape (..., 16)
        b: Right operand, shape (..., 16)

    Returns:
        Result multivector, shape (..., 16)

    Note:
        Fully expanded, no loops, ONNX compatible.
    """
    r0 = (
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        a[..., 7] * b[..., 7] +
        -a[..., 8] * b[..., 8] +
        a[..., 9] * b[..., 9] +
        a[..., 10] * b[..., 10] +
        -a[..., 11] * b[..., 11] +
        a[..., 12] * b[..., 12] +
        a[..., 13] * b[..., 13] +
        a[..., 14] * b[..., 14] +
        -a[..., 15] * b[..., 15]
    )
    r1 = (
        a[..., 0] * b[..., 1] +
        a[..., 1] * b[..., 0] +
        -a[..., 2] * b[..., 5] +
        -a[..., 3] * b[..., 6] +
        a[..., 4] * b[..., 7] +
        a[..., 5] * b[..., 2] +
        a[..., 6] * b[..., 3] +
        -a[..., 7] * b[..., 4] +
        -a[..., 8] * b[..., 11] +
        a[..., 9] * b[..., 12] +
        a[..., 10] * b[..., 13] +
        -a[..., 11] * b[..., 8] +
        a[..., 12] * b[..., 9] +
        a[..., 13] * b[..., 10] +
        -a[..., 14] * b[..., 15] +
        a[..., 15] * b[..., 14]
    )
    r2 = (
        a[..., 0] * b[..., 2] +
        a[..., 1] * b[..., 5] +
        a[..., 2] * b[..., 0] +
        -a[..., 3] * b[..., 8] +
        a[..., 4] * b[..., 9] +
        -a[..., 5] * b[..., 1] +
        a[..., 6] * b[..., 11] +
        -a[..., 7] * b[..., 12] +
        a[..., 8] * b[..., 3] +
        -a[..., 9] * b[..., 4] +
        a[..., 10] * b[..., 14] +
        a[..., 11] * b[..., 6] +
        -a[..., 12] * b[..., 7] +
        a[..., 13] * b[..., 15] +
        a[..., 14] * b[..., 10] +
        -a[..., 15] * b[..., 13]
    )
    r3 = (
        a[..., 0] * b[..., 3] +
        a[..., 1] * b[..., 6] +
        a[..., 2] * b[..., 8] +
        a[..., 3] * b[..., 0] +
        a[..., 4] * b[..., 10] +
        -a[..., 5] * b[..., 11] +
        -a[..., 6] * b[..., 1] +
        -a[..., 7] * b[..., 13] +
        -a[..., 8] * b[..., 2] +
        -a[..., 9] * b[..., 14] +
        -a[..., 10] * b[..., 4] +
        -a[..., 11] * b[..., 5] +
        -a[..., 12] * b[..., 15] +
        -a[..., 13] * b[..., 7] +
        -a[..., 14] * b[..., 9] +
        a[..., 15] * b[..., 12]
    )
    r4 = (
        a[..., 0] * b[..., 4] +
        a[..., 1] * b[..., 7] +
        a[..., 2] * b[..., 9] +
        a[..., 3] * b[..., 10] +
        a[..., 4] * b[..., 0] +
        -a[..., 5] * b[..., 12] +
        -a[..., 6] * b[..., 13] +
        -a[..., 7] * b[..., 1] +
        -a[..., 8] * b[..., 14] +
        -a[..., 9] * b[..., 2] +
        -a[..., 10] * b[..., 3] +
        -a[..., 11] * b[..., 15] +
        -a[..., 12] * b[..., 5] +
        -a[..., 13] * b[..., 6] +
        -a[..., 14] * b[..., 8] +
        a[..., 15] * b[..., 11]
    )
    r5 = (
        a[..., 0] * b[..., 5] +
        a[..., 1] * b[..., 2] +
        -a[..., 2] * b[..., 1] +
        a[..., 3] * b[..., 11] +
        -a[..., 4] * b[..., 12] +
        a[..., 5] * b[..., 0] +
        -a[..., 6] * b[..., 8] +
        a[..., 7] * b[..., 9] +
        a[..., 8] * b[..., 6] +
        -a[..., 9] * b[..., 7] +
        a[..., 10] * b[..., 15] +
        a[..., 11] * b[..., 3] +
        -a[..., 12] * b[..., 4] +
        a[..., 13] * b[..., 14] +
        -a[..., 14] * b[..., 13] +
        a[..., 15] * b[..., 10]
    )
    r6 = (
        a[..., 0] * b[..., 6] +
        a[..., 1] * b[..., 3] +
        -a[..., 2] * b[..., 11] +
        -a[..., 3] * b[..., 1] +
        -a[..., 4] * b[..., 13] +
        a[..., 5] * b[..., 8] +
        a[..., 6] * b[..., 0] +
        a[..., 7] * b[..., 10] +
        -a[..., 8] * b[..., 5] +
        -a[..., 9] * b[..., 15] +
        -a[..., 10] * b[..., 7] +
        -a[..., 11] * b[..., 2] +
        -a[..., 12] * b[..., 14] +
        -a[..., 13] * b[..., 4] +
        a[..., 14] * b[..., 12] +
        -a[..., 15] * b[..., 9]
    )
    r7 = (
        a[..., 0] * b[..., 7] +
        a[..., 1] * b[..., 4] +
        -a[..., 2] * b[..., 12] +
        -a[..., 3] * b[..., 13] +
        -a[..., 4] * b[..., 1] +
        a[..., 5] * b[..., 9] +
        a[..., 6] * b[..., 10] +
        a[..., 7] * b[..., 0] +
        -a[..., 8] * b[..., 15] +
        -a[..., 9] * b[..., 5] +
        -a[..., 10] * b[..., 6] +
        -a[..., 11] * b[..., 14] +
        -a[..., 12] * b[..., 2] +
        -a[..., 13] * b[..., 3] +
        a[..., 14] * b[..., 11] +
        -a[..., 15] * b[..., 8]
    )
    r8 = (
        a[..., 0] * b[..., 8] +
        a[..., 1] * b[..., 11] +
        a[..., 2] * b[..., 3] +
        -a[..., 3] * b[..., 2] +
        -a[..., 4] * b[..., 14] +
        -a[..., 5] * b[..., 6] +
        a[..., 6] * b[..., 5] +
        a[..., 7] * b[..., 15] +
        a[..., 8] * b[..., 0] +
        a[..., 9] * b[..., 10] +
        -a[..., 10] * b[..., 9] +
        a[..., 11] * b[..., 1] +
        a[..., 12] * b[..., 13] +
        -a[..., 13] * b[..., 12] +
        -a[..., 14] * b[..., 4] +
        a[..., 15] * b[..., 7]
    )
    r9 = (
        a[..., 0] * b[..., 9] +
        a[..., 1] * b[..., 12] +
        a[..., 2] * b[..., 4] +
        -a[..., 3] * b[..., 14] +
        -a[..., 4] * b[..., 2] +
        -a[..., 5] * b[..., 7] +
        a[..., 6] * b[..., 15] +
        a[..., 7] * b[..., 5] +
        a[..., 8] * b[..., 10] +
        a[..., 9] * b[..., 0] +
        -a[..., 10] * b[..., 8] +
        a[..., 11] * b[..., 13] +
        a[..., 12] * b[..., 1] +
        -a[..., 13] * b[..., 11] +
        -a[..., 14] * b[..., 3] +
        a[..., 15] * b[..., 6]
    )
    r10 = (
        a[..., 0] * b[..., 10] +
        a[..., 1] * b[..., 13] +
        a[..., 2] * b[..., 14] +
        a[..., 3] * b[..., 4] +
        -a[..., 4] * b[..., 3] +
        -a[..., 5] * b[..., 15] +
        -a[..., 6] * b[..., 7] +
        a[..., 7] * b[..., 6] +
        -a[..., 8] * b[..., 9] +
        a[..., 9] * b[..., 8] +
        a[..., 10] * b[..., 0] +
        -a[..., 11] * b[..., 12] +
        a[..., 12] * b[..., 11] +
        a[..., 13] * b[..., 1] +
        a[..., 14] * b[..., 2] +
        -a[..., 15] * b[..., 5]
    )
    r11 = (
        a[..., 0] * b[..., 11] +
        a[..., 1] * b[..., 8] +
        -a[..., 2] * b[..., 6] +
        a[..., 3] * b[..., 5] +
        a[..., 4] * b[..., 15] +
        a[..., 5] * b[..., 3] +
        -a[..., 6] * b[..., 2] +
        -a[..., 7] * b[..., 14] +
        a[..., 8] * b[..., 1] +
        a[..., 9] * b[..., 13] +
        -a[..., 10] * b[..., 12] +
        a[..., 11] * b[..., 0] +
        a[..., 12] * b[..., 10] +
        -a[..., 13] * b[..., 9] +
        a[..., 14] * b[..., 7] +
        -a[..., 15] * b[..., 4]
    )
    r12 = (
        a[..., 0] * b[..., 12] +
        a[..., 1] * b[..., 9] +
        -a[..., 2] * b[..., 7] +
        a[..., 3] * b[..., 15] +
        a[..., 4] * b[..., 5] +
        a[..., 5] * b[..., 4] +
        -a[..., 6] * b[..., 14] +
        -a[..., 7] * b[..., 2] +
        a[..., 8] * b[..., 13] +
        a[..., 9] * b[..., 1] +
        -a[..., 10] * b[..., 11] +
        a[..., 11] * b[..., 10] +
        a[..., 12] * b[..., 0] +
        -a[..., 13] * b[..., 8] +
        a[..., 14] * b[..., 6] +
        -a[..., 15] * b[..., 3]
    )
    r13 = (
        a[..., 0] * b[..., 13] +
        a[..., 1] * b[..., 10] +
        -a[..., 2] * b[..., 15] +
        -a[..., 3] * b[..., 7] +
        a[..., 4] * b[..., 6] +
        a[..., 5] * b[..., 14] +
        a[..., 6] * b[..., 4] +
        -a[..., 7] * b[..., 3] +
        -a[..., 8] * b[..., 12] +
        a[..., 9] * b[..., 11] +
        a[..., 10] * b[..., 1] +
        -a[..., 11] * b[..., 9] +
        a[..., 12] * b[..., 8] +
        a[..., 13] * b[..., 0] +
        -a[..., 14] * b[..., 5] +
        a[..., 15] * b[..., 2]
    )
    r14 = (
        a[..., 0] * b[..., 14] +
        a[..., 1] * b[..., 15] +
        a[..., 2] * b[..., 10] +
        -a[..., 3] * b[..., 9] +
        a[..., 4] * b[..., 8] +
        -a[..., 5] * b[..., 13] +
        a[..., 6] * b[..., 12] +
        -a[..., 7] * b[..., 11] +
        a[..., 8] * b[..., 4] +
        -a[..., 9] * b[..., 3] +
        a[..., 10] * b[..., 2] +
        a[..., 11] * b[..., 7] +
        -a[..., 12] * b[..., 6] +
        a[..., 13] * b[..., 5] +
        a[..., 14] * b[..., 0] +
        -a[..., 15] * b[..., 1]
    )
    r15 = (
        a[..., 0] * b[..., 15] +
        a[..., 1] * b[..., 14] +
        -a[..., 2] * b[..., 13] +
        a[..., 3] * b[..., 12] +
        -a[..., 4] * b[..., 11] +
        a[..., 5] * b[..., 10] +
        -a[..., 6] * b[..., 9] +
        a[..., 7] * b[..., 8] +
        a[..., 8] * b[..., 7] +
        -a[..., 9] * b[..., 6] +
        a[..., 10] * b[..., 5] +
        a[..., 11] * b[..., 4] +
        -a[..., 12] * b[..., 3] +
        a[..., 13] * b[..., 2] +
        -a[..., 14] * b[..., 1] +
        a[..., 15] * b[..., 0]
    )

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Reverse Operation
# =============================================================================

@torch.jit.script
def reverse_full(mv: Tensor) -> Tensor:
    """
    Compute the reverse of a multivector.

    For grade k: coefficient *= (-1)^(k*(k-1)/2)

    Args:
        mv: Input multivector, shape (..., 16)

    Returns:
        Reversed multivector, shape (..., 16)
    """
    r0 = mv[..., 0]
    r1 = mv[..., 1]
    r2 = mv[..., 2]
    r3 = mv[..., 3]
    r4 = mv[..., 4]
    r5 = -mv[..., 5]
    r6 = -mv[..., 6]
    r7 = -mv[..., 7]
    r8 = -mv[..., 8]
    r9 = -mv[..., 9]
    r10 = -mv[..., 10]
    r11 = -mv[..., 11]
    r12 = -mv[..., 12]
    r13 = -mv[..., 13]
    r14 = -mv[..., 14]
    r15 = mv[..., 15]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Sparse Operations (EvenVersor[8] x Point[4])
# =============================================================================

# EvenVersor sparse indices: (0, 5, 6, 7, 8, 9, 10, 15)
# Point sparse indices: (1, 2, 3, 4)

@torch.jit.script
def upgc_encode(x: Tensor) -> Tensor:
    """
    Encode 2D vector to UPGC point representation.

    X = n_o + x + 0.5|x|^2 * n_inf

    Where:
        n_o = 0.5 * (e- - e+)   -> coefficients: e+ = -0.5, e- = 0.5
        n_inf = e- + e+         -> coefficients: e+ = 1, e- = 1

    Args:
        x: 2D vector, shape (..., 2)

    Returns:
        UPGC point, shape (..., 4)
    """
    x1 = x[..., 0]
    x2 = x[..., 1]

    half_norm_sq = 0.5 * (x1 * x1 + x2 * x2)

    r0 = x1  # e1
    r1 = x2  # e2
    r2 = -0.5 + half_norm_sq  # e+
    r3 = 0.5 + half_norm_sq  # e-

    return torch.stack([r0, r1, r2, r3], dim=-1)


@torch.jit.script
def upgc_decode(point: Tensor) -> Tensor:
    """
    Decode UPGC point to 2D vector.

    Extracts the first 2 components (euclidean part).

    Args:
        point: UPGC point, shape (..., 4)

    Returns:
        2D vector, shape (..., 2)
    """
    return point[..., :2]


@torch.jit.script
def reverse_even_versor(ev: Tensor) -> Tensor:
    """
    Compute reverse of an EvenVersor (sparse 8-component version).

    Args:
        ev: EvenVersor, shape (..., 8)

    Returns:
        Reversed EvenVersor, shape (..., 8)
    """
    r0 = ev[..., 0]  # 1: keep
    r1 = -ev[..., 1]  # e1e2: negate
    r2 = -ev[..., 2]  # e1e+: negate
    r3 = -ev[..., 3]  # e1e-: negate
    r4 = -ev[..., 4]  # e2e+: negate
    r5 = -ev[..., 5]  # e2e-: negate
    r6 = -ev[..., 6]  # e+e-: negate
    r7 = ev[..., 7]  # e1e2e+e-: keep

    return torch.stack([r0, r1, r2, r3, r4, r5, r6, r7], dim=-1)


@torch.jit.script
def sandwich_product_sparse(ev: Tensor, point: Tensor) -> Tensor:
    """
    Compute sparse sandwich product: M × X × M̃

    Optimized for:
        - EvenVersor M: 8 components
        - Point X: 4 components
        - Output: 4 components

    Args:
        ev: EvenVersor, shape (..., 8)
        point: UPGC point, shape (..., 4)

    Returns:
        Transformed point, shape (..., 4)

    Note:
        Total multiplications: 256 (vs 512 for naive)
    """
    # EvenVersor components (sparse)
    m0 = ev[..., 0]  # 1
    m1 = ev[..., 1]  # e1e2
    m2 = ev[..., 2]  # e1e+
    m3 = ev[..., 3]  # e1e-
    m4 = ev[..., 4]  # e2e+
    m5 = ev[..., 5]  # e2e-
    m6 = ev[..., 6]  # e+e-
    m7 = ev[..., 7]  # e1e2e+e-

    # Point components (sparse)
    p0 = point[..., 0]  # e1
    p1 = point[..., 1]  # e2
    p2 = point[..., 2]  # e+
    p3 = point[..., 3]  # e-

    # EvenVersor reverse
    mr0 = m0
    mr1 = -m1
    mr2 = -m2
    mr3 = -m3
    mr4 = -m4
    mr5 = -m5
    mr6 = -m6
    mr7 = m7

    # Output r0 (e1): 32 terms
    r0 = (
        m0 * p0 * mr0 +
        -m0 * p1 * mr1 +
        -m0 * p2 * mr2 +
        m0 * p3 * mr3 +
        m1 * p0 * mr1 +
        m1 * p1 * mr0 +
        -m1 * p2 * mr4 +
        m1 * p3 * mr5 +
        m2 * p0 * mr2 +
        m2 * p1 * mr4 +
        m2 * p2 * mr0 +
        m2 * p3 * mr6 +
        -m3 * p0 * mr3 +
        -m3 * p1 * mr5 +
        -m3 * p2 * mr6 +
        -m3 * p3 * mr0 +
        -m4 * p0 * mr4 +
        m4 * p1 * mr2 +
        -m4 * p2 * mr1 +
        -m4 * p3 * mr7 +
        m5 * p0 * mr5 +
        -m5 * p1 * mr3 +
        m5 * p2 * mr7 +
        m5 * p3 * mr1 +
        m6 * p0 * mr6 +
        -m6 * p1 * mr7 +
        -m6 * p2 * mr3 +
        m6 * p3 * mr2 +
        m7 * p0 * mr7 +
        m7 * p1 * mr6 +
        -m7 * p2 * mr5 +
        m7 * p3 * mr4
    )

    # Output r1 (e2): 32 terms
    r1 = (
        m0 * p0 * mr1 +
        m0 * p1 * mr0 +
        -m0 * p2 * mr4 +
        m0 * p3 * mr5 +
        -m1 * p0 * mr0 +
        m1 * p1 * mr1 +
        m1 * p2 * mr2 +
        -m1 * p3 * mr3 +
        m2 * p0 * mr4 +
        -m2 * p1 * mr2 +
        m2 * p2 * mr1 +
        m2 * p3 * mr7 +
        -m3 * p0 * mr5 +
        m3 * p1 * mr3 +
        -m3 * p2 * mr7 +
        -m3 * p3 * mr1 +
        m4 * p0 * mr2 +
        m4 * p1 * mr4 +
        m4 * p2 * mr0 +
        m4 * p3 * mr6 +
        -m5 * p0 * mr3 +
        -m5 * p1 * mr5 +
        -m5 * p2 * mr6 +
        -m5 * p3 * mr0 +
        m6 * p0 * mr7 +
        m6 * p1 * mr6 +
        -m6 * p2 * mr5 +
        m6 * p3 * mr4 +
        -m7 * p0 * mr6 +
        m7 * p1 * mr7 +
        m7 * p2 * mr3 +
        -m7 * p3 * mr2
    )

    # Output r2 (e+): 32 terms
    r2 = (
        m0 * p0 * mr2 +
        m0 * p1 * mr4 +
        m0 * p2 * mr0 +
        m0 * p3 * mr6 +
        -m1 * p0 * mr4 +
        m1 * p1 * mr2 +
        -m1 * p2 * mr1 +
        -m1 * p3 * mr7 +
        -m2 * p0 * mr0 +
        m2 * p1 * mr1 +
        m2 * p2 * mr2 +
        -m2 * p3 * mr3 +
        -m3 * p0 * mr6 +
        m3 * p1 * mr7 +
        m3 * p2 * mr3 +
        -m3 * p3 * mr2 +
        -m4 * p0 * mr1 +
        -m4 * p1 * mr0 +
        m4 * p2 * mr4 +
        -m4 * p3 * mr5 +
        -m5 * p0 * mr7 +
        -m5 * p1 * mr6 +
        m5 * p2 * mr5 +
        -m5 * p3 * mr4 +
        -m6 * p0 * mr3 +
        -m6 * p1 * mr5 +
        -m6 * p2 * mr6 +
        -m6 * p3 * mr0 +
        m7 * p0 * mr5 +
        -m7 * p1 * mr3 +
        m7 * p2 * mr7 +
        m7 * p3 * mr1
    )

    # Output r3 (e-): 32 terms
    r3 = (
        m0 * p0 * mr3 +
        m0 * p1 * mr5 +
        m0 * p2 * mr6 +
        m0 * p3 * mr0 +
        -m1 * p0 * mr5 +
        m1 * p1 * mr3 +
        -m1 * p2 * mr7 +
        -m1 * p3 * mr1 +
        -m2 * p0 * mr6 +
        m2 * p1 * mr7 +
        m2 * p2 * mr3 +
        -m2 * p3 * mr2 +
        -m3 * p0 * mr0 +
        m3 * p1 * mr1 +
        m3 * p2 * mr2 +
        -m3 * p3 * mr3 +
        -m4 * p0 * mr7 +
        -m4 * p1 * mr6 +
        m4 * p2 * mr5 +
        -m4 * p3 * mr4 +
        -m5 * p0 * mr1 +
        -m5 * p1 * mr0 +
        m5 * p2 * mr4 +
        -m5 * p3 * mr5 +
        -m6 * p0 * mr2 +
        -m6 * p1 * mr4 +
        -m6 * p2 * mr0 +
        -m6 * p3 * mr6 +
        m7 * p0 * mr4 +
        -m7 * p1 * mr2 +
        m7 * p2 * mr1 +
        m7 * p3 * mr7
    )

    return torch.stack([r0, r1, r2, r3], dim=-1)


# =============================================================================
# EvenVersor Composition
# =============================================================================

@torch.jit.script
def compose_even_versor(v1: Tensor, v2: Tensor) -> Tensor:
    """
    Compose two EvenVersors via geometric product.

    Args:
        v1: First EvenVersor, shape (..., 8)
        v2: Second EvenVersor, shape (..., 8)

    Returns:
        Composed EvenVersor, shape (..., 8)
    """
    # v1 components
    v1_0 = v1[..., 0]  # 1
    v1_1 = v1[..., 1]  # e1e2
    v1_2 = v1[..., 2]  # e1e+
    v1_3 = v1[..., 3]  # e1e-
    v1_4 = v1[..., 4]  # e2e+
    v1_5 = v1[..., 5]  # e2e-
    v1_6 = v1[..., 6]  # e+e-
    v1_7 = v1[..., 7]  # e1e2e+e-

    # v2 components
    v2_0 = v2[..., 0]  # 1
    v2_1 = v2[..., 1]  # e1e2
    v2_2 = v2[..., 2]  # e1e+
    v2_3 = v2[..., 3]  # e1e-
    v2_4 = v2[..., 4]  # e2e+
    v2_5 = v2[..., 5]  # e2e-
    v2_6 = v2[..., 6]  # e+e-
    v2_7 = v2[..., 7]  # e1e2e+e-

    # r0 (1): 8 terms
    r0 = (
        v1_0 * v2_0 +
        -v1_1 * v2_1 +
        -v1_2 * v2_2 +
        v1_3 * v2_3 +
        -v1_4 * v2_4 +
        v1_5 * v2_5 +
        v1_6 * v2_6 +
        -v1_7 * v2_7
    )
    # r1 (e1e2): 8 terms
    r1 = (
        v1_0 * v2_1 +
        v1_1 * v2_0 +
        -v1_2 * v2_4 +
        v1_3 * v2_5 +
        v1_4 * v2_2 +
        -v1_5 * v2_3 +
        v1_6 * v2_7 +
        v1_7 * v2_6
    )
    # r2 (e1e+): 8 terms
    r2 = (
        v1_0 * v2_2 +
        v1_1 * v2_4 +
        v1_2 * v2_0 +
        v1_3 * v2_6 +
        -v1_4 * v2_1 +
        -v1_5 * v2_7 +
        -v1_6 * v2_3 +
        -v1_7 * v2_5
    )
    # r3 (e1e-): 8 terms
    r3 = (
        v1_0 * v2_3 +
        v1_1 * v2_5 +
        v1_2 * v2_6 +
        v1_3 * v2_0 +
        -v1_4 * v2_7 +
        -v1_5 * v2_1 +
        -v1_6 * v2_2 +
        -v1_7 * v2_4
    )
    # r4 (e2e+): 8 terms
    r4 = (
        v1_0 * v2_4 +
        -v1_1 * v2_2 +
        v1_2 * v2_1 +
        v1_3 * v2_7 +
        v1_4 * v2_0 +
        v1_5 * v2_6 +
        -v1_6 * v2_5 +
        v1_7 * v2_3
    )
    # r5 (e2e-): 8 terms
    r5 = (
        v1_0 * v2_5 +
        -v1_1 * v2_3 +
        v1_2 * v2_7 +
        v1_3 * v2_1 +
        v1_4 * v2_6 +
        v1_5 * v2_0 +
        -v1_6 * v2_4 +
        v1_7 * v2_2
    )
    # r6 (e+e-): 8 terms
    r6 = (
        v1_0 * v2_6 +
        -v1_1 * v2_7 +
        -v1_2 * v2_3 +
        v1_3 * v2_2 +
        -v1_4 * v2_5 +
        v1_5 * v2_4 +
        v1_6 * v2_0 +
        -v1_7 * v2_1
    )
    # r7 (e1e2e+e-): 8 terms
    r7 = (
        v1_0 * v2_7 +
        v1_1 * v2_6 +
        -v1_2 * v2_5 +
        v1_3 * v2_4 +
        v1_4 * v2_3 +
        -v1_5 * v2_2 +
        v1_6 * v2_1 +
        v1_7 * v2_0
    )

    return torch.stack([r0, r1, r2, r3, r4, r5, r6, r7], dim=-1)

# =============================================================================
# Similitude Composition (CGA-specific accelerated)
# =============================================================================

@torch.jit.script
def compose_similitude(s1: Tensor, s2: Tensor) -> Tensor:
    """
    Compose two Similitudes via optimized geometric product.

    Similitude constraint: ei+ = ei- (translation components equal)
    This allows 30-50% speedup over general EvenVersor composition.

    Args:
        s1: First Similitude, shape (..., 8)
        s2: Second Similitude, shape (..., 8)

    Returns:
        Composed Similitude, shape (..., 8)
    """
    # Note: Currently same as compose_even_versor
    # Future optimization: exploit ei+ = ei- constraint
    # s1 components
    s1_0 = s1[..., 0]  # 1
    s1_1 = s1[..., 1]  # e1e2
    s1_2 = s1[..., 2]  # e1e+
    s1_3 = s1[..., 3]  # e1e-
    s1_4 = s1[..., 4]  # e2e+
    s1_5 = s1[..., 5]  # e2e-
    s1_6 = s1[..., 6]  # e+e-
    s1_7 = s1[..., 7]  # e1e2e+e-

    # s2 components
    s2_0 = s2[..., 0]  # 1
    s2_1 = s2[..., 1]  # e1e2
    s2_2 = s2[..., 2]  # e1e+
    s2_3 = s2[..., 3]  # e1e-
    s2_4 = s2[..., 4]  # e2e+
    s2_5 = s2[..., 5]  # e2e-
    s2_6 = s2[..., 6]  # e+e-
    s2_7 = s2[..., 7]  # e1e2e+e-

    # r0 (1): 8 terms
    r0 = (
        s1_0 * s2_0 +
        -s1_1 * s2_1 +
        -s1_2 * s2_2 +
        s1_3 * s2_3 +
        -s1_4 * s2_4 +
        s1_5 * s2_5 +
        s1_6 * s2_6 +
        -s1_7 * s2_7
    )
    # r1 (e1e2): 8 terms
    r1 = (
        s1_0 * s2_1 +
        s1_1 * s2_0 +
        -s1_2 * s2_4 +
        s1_3 * s2_5 +
        s1_4 * s2_2 +
        -s1_5 * s2_3 +
        s1_6 * s2_7 +
        s1_7 * s2_6
    )
    # r2 (e1e+): 8 terms
    r2 = (
        s1_0 * s2_2 +
        s1_1 * s2_4 +
        s1_2 * s2_0 +
        s1_3 * s2_6 +
        -s1_4 * s2_1 +
        -s1_5 * s2_7 +
        -s1_6 * s2_3 +
        -s1_7 * s2_5
    )
    # r3 (e1e-): 8 terms
    r3 = (
        s1_0 * s2_3 +
        s1_1 * s2_5 +
        s1_2 * s2_6 +
        s1_3 * s2_0 +
        -s1_4 * s2_7 +
        -s1_5 * s2_1 +
        -s1_6 * s2_2 +
        -s1_7 * s2_4
    )
    # r4 (e2e+): 8 terms
    r4 = (
        s1_0 * s2_4 +
        -s1_1 * s2_2 +
        s1_2 * s2_1 +
        s1_3 * s2_7 +
        s1_4 * s2_0 +
        s1_5 * s2_6 +
        -s1_6 * s2_5 +
        s1_7 * s2_3
    )
    # r5 (e2e-): 8 terms
    r5 = (
        s1_0 * s2_5 +
        -s1_1 * s2_3 +
        s1_2 * s2_7 +
        s1_3 * s2_1 +
        s1_4 * s2_6 +
        s1_5 * s2_0 +
        -s1_6 * s2_4 +
        s1_7 * s2_2
    )
    # r6 (e+e-): 8 terms
    r6 = (
        s1_0 * s2_6 +
        -s1_1 * s2_7 +
        -s1_2 * s2_3 +
        s1_3 * s2_2 +
        -s1_4 * s2_5 +
        s1_5 * s2_4 +
        s1_6 * s2_0 +
        -s1_7 * s2_1
    )
    # r7 (e1e2e+e-): 8 terms
    r7 = (
        s1_0 * s2_7 +
        s1_1 * s2_6 +
        -s1_2 * s2_5 +
        s1_3 * s2_4 +
        s1_4 * s2_3 +
        -s1_5 * s2_2 +
        s1_6 * s2_1 +
        s1_7 * s2_0
    )

    return torch.stack([r0, r1, r2, r3, r4, r5, r6, r7], dim=-1)

# =============================================================================
# Similitude Sandwich Product (CGA-specific accelerated)
# =============================================================================

@torch.jit.script
def sandwich_product_similitude(similitude: Tensor, point: Tensor) -> Tensor:
    """
    Compute sandwich product S × X × ~S for Similitude.

    Faster than sandwich_product_sparse by exploiting Similitude constraints.

    Args:
        similitude: Similitude, shape (..., 8)
        point: UPGC point, shape (..., 4)

    Returns:
        Transformed point, shape (..., 4)
    """
    # Currently delegates to sandwich_product_sparse
    # Future optimization: exploit ei+ = ei- constraint
    return sandwich_product_sparse(similitude, point)

# =============================================================================
# Geometric Inner Product (Metric Inner Product)
# =============================================================================

@torch.jit.script
def inner_product_full(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute geometric inner product with CGA metric.

    Args:
        a: First multivector, shape (..., 16)
        b: Second multivector, shape (..., 16)

    Returns:
        Scalar inner product, shape (..., 1)

    Note:
        Uses fused sign flipping: res = sum(a[i] * b[i] * METRIC_SIGNS[i])
    """
    r = (
        a[..., 0] * b[..., 0] +  # 1² = 1
        a[..., 1] * b[..., 1] +  # e1² = 1
        a[..., 2] * b[..., 2] +  # e2² = 1
        a[..., 3] * b[..., 3] +  # e+² = 1
        -a[..., 4] * b[..., 4] +  # e-² = -1
        -a[..., 5] * b[..., 5] +  # e1e2² = -1
        -a[..., 6] * b[..., 6] +  # e1e+² = -1
        a[..., 7] * b[..., 7] +  # e1e-² = 1
        -a[..., 8] * b[..., 8] +  # e2e+² = -1
        a[..., 9] * b[..., 9] +  # e2e-² = 1
        a[..., 10] * b[..., 10] +  # e+e-² = 1
        -a[..., 11] * b[..., 11] +  # e1e2e+² = -1
        a[..., 12] * b[..., 12] +  # e1e2e-² = 1
        a[..., 13] * b[..., 13] +  # e1e+e-² = 1
        a[..., 14] * b[..., 14] +  # e2e+e-² = 1
        -a[..., 15] * b[..., 15]  # e1e2e+e-² = -1
    )
    return r.unsqueeze(-1)

# =============================================================================
# Bivector Squared Scalar (Helper for exp_bivector)
# =============================================================================

@torch.jit.script
def bivector_squared_scalar(B: Tensor) -> Tensor:
    """
    Compute the scalar part of B².

    Args:
        B: Bivector, shape (..., 6)

    Returns:
        Scalar B² value, shape (...,)
    """
    r = (
        -B[..., 0] * B[..., 0] +
        -B[..., 1] * B[..., 1] +
        B[..., 2] * B[..., 2] +
        -B[..., 3] * B[..., 3] +
        B[..., 4] * B[..., 4] +
        B[..., 5] * B[..., 5]
    )
    return r

# =============================================================================
# Bivector Exponential Map
# =============================================================================

@torch.jit.script
def exp_bivector(B: Tensor) -> Tensor:
    """
    Compute exponential map from Bivector to EvenVersor.

    exp(B) = cos(θ) + sinc(θ) * B
    where θ² = -B² (for rotation bivectors)

    Args:
        B: Bivector, shape (..., 6)

    Returns:
        EvenVersor, shape (..., 8)

    Note:
        Uses torch.sinc for numerical stability at θ→0
    """
    # Compute B² scalar
    B_sq = bivector_squared_scalar(B)

    # θ² = -B² (for rotation bivectors, B² is negative)
    theta_sq = torch.clamp(-B_sq, min=1e-12)
    theta = torch.sqrt(theta_sq)

    # cos(θ) and sinc(θ) = sin(θ)/θ
    cos_theta = torch.cos(theta)
    # torch.sinc(x) = sin(πx)/(πx), so sinc(θ/π) = sin(θ)/θ
    sinc_theta = torch.sinc(theta / 3.141592653589793)

    # Build even_versor: scalar part = cos(θ), bivector parts = sinc(θ) * B
    r0 = cos_theta  # 1
    r1 = sinc_theta * B[..., 0]  # e1e2
    r2 = sinc_theta * B[..., 1]  # e1e+
    r3 = sinc_theta * B[..., 2]  # e1e-
    r4 = sinc_theta * B[..., 3]  # e2e+
    r5 = sinc_theta * B[..., 4]  # e2e-
    r6 = sinc_theta * B[..., 5]  # e+e-
    r7 = torch.zeros_like(cos_theta)  # e1e2e+e-

    return torch.stack([r0, r1, r2, r3, r4, r5, r6, r7], dim=-1)

# =============================================================================
# Outer Product (Wedge Product)
# =============================================================================

@torch.jit.script
def outer_product_full(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute outer product (wedge product).

    a ∧ b = <a * b>_{grade(a) + grade(b)}

    Args:
        a: First multivector, shape (..., 16)
        b: Second multivector, shape (..., 16)

    Returns:
        Wedge product, shape (..., 16)
    """
    r0 = a[..., 0] * b[..., 0]  # 1
    r1 = a[..., 0] * b[..., 1] + a[..., 1] * b[..., 0]  # e1
    r2 = a[..., 0] * b[..., 2] + a[..., 2] * b[..., 0]  # e2
    r3 = a[..., 0] * b[..., 3] + a[..., 3] * b[..., 0]  # e+
    r4 = a[..., 0] * b[..., 4] + a[..., 4] * b[..., 0]  # e-
    r5 = (  # e1e2
        a[..., 0] * b[..., 5] +
        a[..., 1] * b[..., 2] +
        -a[..., 2] * b[..., 1] +
        a[..., 5] * b[..., 0]
    )
    r6 = (  # e1e+
        a[..., 0] * b[..., 6] +
        a[..., 1] * b[..., 3] +
        -a[..., 3] * b[..., 1] +
        a[..., 6] * b[..., 0]
    )
    r7 = (  # e1e-
        a[..., 0] * b[..., 7] +
        a[..., 1] * b[..., 4] +
        -a[..., 4] * b[..., 1] +
        a[..., 7] * b[..., 0]
    )
    r8 = (  # e2e+
        a[..., 0] * b[..., 8] +
        a[..., 2] * b[..., 3] +
        -a[..., 3] * b[..., 2] +
        a[..., 8] * b[..., 0]
    )
    r9 = (  # e2e-
        a[..., 0] * b[..., 9] +
        a[..., 2] * b[..., 4] +
        -a[..., 4] * b[..., 2] +
        a[..., 9] * b[..., 0]
    )
    r10 = (  # e+e-
        a[..., 0] * b[..., 10] +
        a[..., 3] * b[..., 4] +
        -a[..., 4] * b[..., 3] +
        a[..., 10] * b[..., 0]
    )
    r11 = (  # e1e2e+
        a[..., 0] * b[..., 11] +
        a[..., 1] * b[..., 8] +
        -a[..., 2] * b[..., 6] +
        a[..., 3] * b[..., 5] +
        a[..., 5] * b[..., 3] +
        -a[..., 6] * b[..., 2] +
        a[..., 8] * b[..., 1] +
        a[..., 11] * b[..., 0]
    )
    r12 = (  # e1e2e-
        a[..., 0] * b[..., 12] +
        a[..., 1] * b[..., 9] +
        -a[..., 2] * b[..., 7] +
        a[..., 4] * b[..., 5] +
        a[..., 5] * b[..., 4] +
        -a[..., 7] * b[..., 2] +
        a[..., 9] * b[..., 1] +
        a[..., 12] * b[..., 0]
    )
    r13 = (  # e1e+e-
        a[..., 0] * b[..., 13] +
        a[..., 1] * b[..., 10] +
        -a[..., 3] * b[..., 7] +
        a[..., 4] * b[..., 6] +
        a[..., 6] * b[..., 4] +
        -a[..., 7] * b[..., 3] +
        a[..., 10] * b[..., 1] +
        a[..., 13] * b[..., 0]
    )
    r14 = (  # e2e+e-
        a[..., 0] * b[..., 14] +
        a[..., 2] * b[..., 10] +
        -a[..., 3] * b[..., 9] +
        a[..., 4] * b[..., 8] +
        a[..., 8] * b[..., 4] +
        -a[..., 9] * b[..., 3] +
        a[..., 10] * b[..., 2] +
        a[..., 14] * b[..., 0]
    )
    r15 = (  # e1e2e+e-
        a[..., 0] * b[..., 15] +
        a[..., 1] * b[..., 14] +
        -a[..., 2] * b[..., 13] +
        a[..., 3] * b[..., 12] +
        -a[..., 4] * b[..., 11] +
        a[..., 5] * b[..., 10] +
        -a[..., 6] * b[..., 9] +
        a[..., 7] * b[..., 8] +
        a[..., 8] * b[..., 7] +
        -a[..., 9] * b[..., 6] +
        a[..., 10] * b[..., 5] +
        a[..., 11] * b[..., 4] +
        -a[..., 12] * b[..., 3] +
        a[..., 13] * b[..., 2] +
        -a[..., 14] * b[..., 1] +
        a[..., 15] * b[..., 0]
    )

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Left Contraction
# =============================================================================

@torch.jit.script
def left_contraction_full(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute left contraction.

    a ⌋ b = <a * b>_{grade(b) - grade(a)} if grade(a) <= grade(b), else 0

    Args:
        a: First multivector, shape (..., 16)
        b: Second multivector, shape (..., 16)

    Returns:
        Left contraction result, shape (..., 16)
    """
    r0 = (  # 1
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        a[..., 7] * b[..., 7] +
        -a[..., 8] * b[..., 8] +
        a[..., 9] * b[..., 9] +
        a[..., 10] * b[..., 10] +
        -a[..., 11] * b[..., 11] +
        a[..., 12] * b[..., 12] +
        a[..., 13] * b[..., 13] +
        a[..., 14] * b[..., 14] +
        -a[..., 15] * b[..., 15]
    )
    r1 = (  # e1
        a[..., 0] * b[..., 1] +
        -a[..., 2] * b[..., 5] +
        -a[..., 3] * b[..., 6] +
        a[..., 4] * b[..., 7] +
        -a[..., 8] * b[..., 11] +
        a[..., 9] * b[..., 12] +
        a[..., 10] * b[..., 13] +
        -a[..., 14] * b[..., 15]
    )
    r2 = (  # e2
        a[..., 0] * b[..., 2] +
        a[..., 1] * b[..., 5] +
        -a[..., 3] * b[..., 8] +
        a[..., 4] * b[..., 9] +
        a[..., 6] * b[..., 11] +
        -a[..., 7] * b[..., 12] +
        a[..., 10] * b[..., 14] +
        a[..., 13] * b[..., 15]
    )
    r3 = (  # e+
        a[..., 0] * b[..., 3] +
        a[..., 1] * b[..., 6] +
        a[..., 2] * b[..., 8] +
        a[..., 4] * b[..., 10] +
        -a[..., 5] * b[..., 11] +
        -a[..., 7] * b[..., 13] +
        -a[..., 9] * b[..., 14] +
        -a[..., 12] * b[..., 15]
    )
    r4 = (  # e-
        a[..., 0] * b[..., 4] +
        a[..., 1] * b[..., 7] +
        a[..., 2] * b[..., 9] +
        a[..., 3] * b[..., 10] +
        -a[..., 5] * b[..., 12] +
        -a[..., 6] * b[..., 13] +
        -a[..., 8] * b[..., 14] +
        -a[..., 11] * b[..., 15]
    )
    r5 = (  # e1e2
        a[..., 0] * b[..., 5] +
        a[..., 3] * b[..., 11] +
        -a[..., 4] * b[..., 12] +
        a[..., 10] * b[..., 15]
    )
    r6 = (  # e1e+
        a[..., 0] * b[..., 6] +
        -a[..., 2] * b[..., 11] +
        -a[..., 4] * b[..., 13] +
        -a[..., 9] * b[..., 15]
    )
    r7 = (  # e1e-
        a[..., 0] * b[..., 7] +
        -a[..., 2] * b[..., 12] +
        -a[..., 3] * b[..., 13] +
        -a[..., 8] * b[..., 15]
    )
    r8 = (  # e2e+
        a[..., 0] * b[..., 8] +
        a[..., 1] * b[..., 11] +
        -a[..., 4] * b[..., 14] +
        a[..., 7] * b[..., 15]
    )
    r9 = (  # e2e-
        a[..., 0] * b[..., 9] +
        a[..., 1] * b[..., 12] +
        -a[..., 3] * b[..., 14] +
        a[..., 6] * b[..., 15]
    )
    r10 = (  # e+e-
        a[..., 0] * b[..., 10] +
        a[..., 1] * b[..., 13] +
        a[..., 2] * b[..., 14] +
        -a[..., 5] * b[..., 15]
    )
    r11 = a[..., 0] * b[..., 11] + a[..., 4] * b[..., 15]  # e1e2e+
    r12 = a[..., 0] * b[..., 12] + a[..., 3] * b[..., 15]  # e1e2e-
    r13 = a[..., 0] * b[..., 13] + -a[..., 2] * b[..., 15]  # e1e+e-
    r14 = a[..., 0] * b[..., 14] + a[..., 1] * b[..., 15]  # e2e+e-
    r15 = a[..., 0] * b[..., 15]  # e1e2e+e-

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Right Contraction
# =============================================================================

@torch.jit.script
def right_contraction_full(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute right contraction.

    a ⌊ b = <a * b>_{grade(a) - grade(b)} if grade(a) >= grade(b), else 0

    Args:
        a: First multivector, shape (..., 16)
        b: Second multivector, shape (..., 16)

    Returns:
        Right contraction result, shape (..., 16)
    """
    r0 = (  # 1
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        a[..., 7] * b[..., 7] +
        -a[..., 8] * b[..., 8] +
        a[..., 9] * b[..., 9] +
        a[..., 10] * b[..., 10] +
        -a[..., 11] * b[..., 11] +
        a[..., 12] * b[..., 12] +
        a[..., 13] * b[..., 13] +
        a[..., 14] * b[..., 14] +
        -a[..., 15] * b[..., 15]
    )
    r1 = (  # e1
        a[..., 1] * b[..., 0] +
        a[..., 5] * b[..., 2] +
        a[..., 6] * b[..., 3] +
        -a[..., 7] * b[..., 4] +
        -a[..., 11] * b[..., 8] +
        a[..., 12] * b[..., 9] +
        a[..., 13] * b[..., 10] +
        a[..., 15] * b[..., 14]
    )
    r2 = (  # e2
        a[..., 2] * b[..., 0] +
        -a[..., 5] * b[..., 1] +
        a[..., 8] * b[..., 3] +
        -a[..., 9] * b[..., 4] +
        a[..., 11] * b[..., 6] +
        -a[..., 12] * b[..., 7] +
        a[..., 14] * b[..., 10] +
        -a[..., 15] * b[..., 13]
    )
    r3 = (  # e+
        a[..., 3] * b[..., 0] +
        -a[..., 6] * b[..., 1] +
        -a[..., 8] * b[..., 2] +
        -a[..., 10] * b[..., 4] +
        -a[..., 11] * b[..., 5] +
        -a[..., 13] * b[..., 7] +
        -a[..., 14] * b[..., 9] +
        a[..., 15] * b[..., 12]
    )
    r4 = (  # e-
        a[..., 4] * b[..., 0] +
        -a[..., 7] * b[..., 1] +
        -a[..., 9] * b[..., 2] +
        -a[..., 10] * b[..., 3] +
        -a[..., 12] * b[..., 5] +
        -a[..., 13] * b[..., 6] +
        -a[..., 14] * b[..., 8] +
        a[..., 15] * b[..., 11]
    )
    r5 = (  # e1e2
        a[..., 5] * b[..., 0] +
        a[..., 11] * b[..., 3] +
        -a[..., 12] * b[..., 4] +
        a[..., 15] * b[..., 10]
    )
    r6 = (  # e1e+
        a[..., 6] * b[..., 0] +
        -a[..., 11] * b[..., 2] +
        -a[..., 13] * b[..., 4] +
        -a[..., 15] * b[..., 9]
    )
    r7 = (  # e1e-
        a[..., 7] * b[..., 0] +
        -a[..., 12] * b[..., 2] +
        -a[..., 13] * b[..., 3] +
        -a[..., 15] * b[..., 8]
    )
    r8 = (  # e2e+
        a[..., 8] * b[..., 0] +
        a[..., 11] * b[..., 1] +
        -a[..., 14] * b[..., 4] +
        a[..., 15] * b[..., 7]
    )
    r9 = (  # e2e-
        a[..., 9] * b[..., 0] +
        a[..., 12] * b[..., 1] +
        -a[..., 14] * b[..., 3] +
        a[..., 15] * b[..., 6]
    )
    r10 = (  # e+e-
        a[..., 10] * b[..., 0] +
        a[..., 13] * b[..., 1] +
        a[..., 14] * b[..., 2] +
        -a[..., 15] * b[..., 5]
    )
    r11 = a[..., 11] * b[..., 0] + -a[..., 15] * b[..., 4]  # e1e2e+
    r12 = a[..., 12] * b[..., 0] + -a[..., 15] * b[..., 3]  # e1e2e-
    r13 = a[..., 13] * b[..., 0] + a[..., 15] * b[..., 2]  # e1e+e-
    r14 = a[..., 14] * b[..., 0] + -a[..., 15] * b[..., 1]  # e2e+e-
    r15 = a[..., 15] * b[..., 0]  # e1e2e+e-

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Grade Selection
# =============================================================================

# Grade masks for grade selection
GRADE_0_MASK = (0,)
GRADE_1_MASK = (1, 2, 3, 4)
GRADE_2_MASK = (5, 6, 7, 8, 9, 10)
GRADE_3_MASK = (11, 12, 13, 14)
GRADE_4_MASK = (15,)

@torch.jit.script
def grade_select(mv: Tensor, grade: int) -> Tensor:
    """
    Extract components of a specific grade.

    Args:
        mv: Multivector, shape (..., 16)
        grade: Grade to extract (0 to 4)

    Returns:
        Grade components (zeros for non-selected grades)
    """
    if grade == 0:
        r0 = mv[..., 0]
        r1 = torch.zeros_like(mv[..., 0])
        r2 = torch.zeros_like(mv[..., 0])
        r3 = torch.zeros_like(mv[..., 0])
        r4 = torch.zeros_like(mv[..., 0])
        r5 = torch.zeros_like(mv[..., 0])
        r6 = torch.zeros_like(mv[..., 0])
        r7 = torch.zeros_like(mv[..., 0])
        r8 = torch.zeros_like(mv[..., 0])
        r9 = torch.zeros_like(mv[..., 0])
        r10 = torch.zeros_like(mv[..., 0])
        r11 = torch.zeros_like(mv[..., 0])
        r12 = torch.zeros_like(mv[..., 0])
        r13 = torch.zeros_like(mv[..., 0])
        r14 = torch.zeros_like(mv[..., 0])
        r15 = torch.zeros_like(mv[..., 0])
        return torch.stack([
            r0, r1, r2, r3, r4, r5, r6, r7,
            r8, r9, r10, r11, r12, r13, r14, r15,
        ], dim=-1)
    elif grade == 1:
        r0 = torch.zeros_like(mv[..., 0])
        r1 = mv[..., 1]
        r2 = mv[..., 2]
        r3 = mv[..., 3]
        r4 = mv[..., 4]
        r5 = torch.zeros_like(mv[..., 0])
        r6 = torch.zeros_like(mv[..., 0])
        r7 = torch.zeros_like(mv[..., 0])
        r8 = torch.zeros_like(mv[..., 0])
        r9 = torch.zeros_like(mv[..., 0])
        r10 = torch.zeros_like(mv[..., 0])
        r11 = torch.zeros_like(mv[..., 0])
        r12 = torch.zeros_like(mv[..., 0])
        r13 = torch.zeros_like(mv[..., 0])
        r14 = torch.zeros_like(mv[..., 0])
        r15 = torch.zeros_like(mv[..., 0])
        return torch.stack([
            r0, r1, r2, r3, r4, r5, r6, r7,
            r8, r9, r10, r11, r12, r13, r14, r15,
        ], dim=-1)
    elif grade == 2:
        r0 = torch.zeros_like(mv[..., 0])
        r1 = torch.zeros_like(mv[..., 0])
        r2 = torch.zeros_like(mv[..., 0])
        r3 = torch.zeros_like(mv[..., 0])
        r4 = torch.zeros_like(mv[..., 0])
        r5 = mv[..., 5]
        r6 = mv[..., 6]
        r7 = mv[..., 7]
        r8 = mv[..., 8]
        r9 = mv[..., 9]
        r10 = mv[..., 10]
        r11 = torch.zeros_like(mv[..., 0])
        r12 = torch.zeros_like(mv[..., 0])
        r13 = torch.zeros_like(mv[..., 0])
        r14 = torch.zeros_like(mv[..., 0])
        r15 = torch.zeros_like(mv[..., 0])
        return torch.stack([
            r0, r1, r2, r3, r4, r5, r6, r7,
            r8, r9, r10, r11, r12, r13, r14, r15,
        ], dim=-1)
    elif grade == 3:
        r0 = torch.zeros_like(mv[..., 0])
        r1 = torch.zeros_like(mv[..., 0])
        r2 = torch.zeros_like(mv[..., 0])
        r3 = torch.zeros_like(mv[..., 0])
        r4 = torch.zeros_like(mv[..., 0])
        r5 = torch.zeros_like(mv[..., 0])
        r6 = torch.zeros_like(mv[..., 0])
        r7 = torch.zeros_like(mv[..., 0])
        r8 = torch.zeros_like(mv[..., 0])
        r9 = torch.zeros_like(mv[..., 0])
        r10 = torch.zeros_like(mv[..., 0])
        r11 = mv[..., 11]
        r12 = mv[..., 12]
        r13 = mv[..., 13]
        r14 = mv[..., 14]
        r15 = torch.zeros_like(mv[..., 0])
        return torch.stack([
            r0, r1, r2, r3, r4, r5, r6, r7,
            r8, r9, r10, r11, r12, r13, r14, r15,
        ], dim=-1)
    elif grade == 4:
        r0 = torch.zeros_like(mv[..., 0])
        r1 = torch.zeros_like(mv[..., 0])
        r2 = torch.zeros_like(mv[..., 0])
        r3 = torch.zeros_like(mv[..., 0])
        r4 = torch.zeros_like(mv[..., 0])
        r5 = torch.zeros_like(mv[..., 0])
        r6 = torch.zeros_like(mv[..., 0])
        r7 = torch.zeros_like(mv[..., 0])
        r8 = torch.zeros_like(mv[..., 0])
        r9 = torch.zeros_like(mv[..., 0])
        r10 = torch.zeros_like(mv[..., 0])
        r11 = torch.zeros_like(mv[..., 0])
        r12 = torch.zeros_like(mv[..., 0])
        r13 = torch.zeros_like(mv[..., 0])
        r14 = torch.zeros_like(mv[..., 0])
        r15 = mv[..., 15]
        return torch.stack([
            r0, r1, r2, r3, r4, r5, r6, r7,
            r8, r9, r10, r11, r12, r13, r14, r15,
        ], dim=-1)
    else:
        return torch.zeros_like(mv)

# =============================================================================
# Dual Operation
# =============================================================================

# Pseudoscalar index: 15, I² = -1
# I^{-1} = I / I² = I * -1.0

@torch.jit.script
def dual(mv: Tensor) -> Tensor:
    """
    Compute the dual of a multivector.

    a* = a ⌋ I^{-1} (left contraction with pseudoscalar inverse)

    Args:
        mv: Multivector, shape (..., 16)

    Returns:
        Dual multivector, shape (..., 16)
    """
    r0 = mv[..., 15]  # 1
    r1 = mv[..., 14]  # e1
    r2 = -mv[..., 13]  # e2
    r3 = mv[..., 12]  # e+
    r4 = mv[..., 11]  # e-
    r5 = -mv[..., 10]  # e1e2
    r6 = mv[..., 9]  # e1e+
    r7 = mv[..., 8]  # e1e-
    r8 = -mv[..., 7]  # e2e+
    r9 = -mv[..., 6]  # e2e-
    r10 = mv[..., 5]  # e+e-
    r11 = -mv[..., 4]  # e1e2e+
    r12 = -mv[..., 3]  # e1e2e-
    r13 = mv[..., 2]  # e1e+e-
    r14 = -mv[..., 1]  # e2e+e-
    r15 = -mv[..., 0]  # e1e2e+e-

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
        r8, r9, r10, r11, r12, r13, r14, r15,
    ], dim=-1)

# =============================================================================
# Normalize Operation
# =============================================================================

@torch.jit.script
def norm_squared(mv: Tensor) -> Tensor:
    """
    Compute squared norm of a multivector.

    |a|² = <a * ~a>_0

    Args:
        mv: Multivector, shape (..., 16)

    Returns:
        Squared norm, shape (...,)
    """
    r = (
        mv[..., 0] * mv[..., 0] +
        mv[..., 1] * mv[..., 1] +
        mv[..., 2] * mv[..., 2] +
        mv[..., 3] * mv[..., 3] +
        -mv[..., 4] * mv[..., 4] +
        mv[..., 5] * mv[..., 5] +
        mv[..., 6] * mv[..., 6] +
        -mv[..., 7] * mv[..., 7] +
        mv[..., 8] * mv[..., 8] +
        -mv[..., 9] * mv[..., 9] +
        -mv[..., 10] * mv[..., 10] +
        mv[..., 11] * mv[..., 11] +
        -mv[..., 12] * mv[..., 12] +
        -mv[..., 13] * mv[..., 13] +
        -mv[..., 14] * mv[..., 14] +
        -mv[..., 15] * mv[..., 15]
    )
    return r


@torch.jit.script
def normalize(mv: Tensor) -> Tensor:
    """
    Normalize a multivector to unit norm.

    Args:
        mv: Multivector, shape (..., 16)

    Returns:
        Normalized multivector, shape (..., 16)

    Note:
        Returns NaN for null multivectors (ONNX compatible)
    """
    norm = torch.sqrt(torch.abs(norm_squared(mv)) + 1e-12)
    return mv / norm.unsqueeze(-1)

# =============================================================================
# Structure Normalize (US9a)
# =============================================================================

ROTOR_INDICES: Tuple[int, ...] = (0, 1)
TRANSLATION_PAIRS: Tuple[Tuple[int, int], ...] = ((2, 3), (4, 5))
DILATION_INDEX: int = 6


@torch.jit.script
def structure_normalize(similitude: Tensor, eps: float = 1e-8) -> Tensor:
    """
    Structure-normalize a Similitude tensor.

    Ensures:
    1. Rotor part (scalar + spatial bivectors) has unit norm
    2. Similitude constraint: eie+ = eie- (no transversion)

    Args:
        similitude: Similitude tensor, shape (..., 8)
        eps: Numerical stability constant

    Returns:
        Structure-normalized Similitude, shape (..., 8)
    """
    result = similitude.clone()

    # Step 1: Normalize Rotor part
    rotor_norm_sq = similitude[..., 0] * similitude[..., 0] + similitude[..., 1] * similitude[..., 1]
    rotor_norm = torch.sqrt(rotor_norm_sq + eps)
    result[..., 0] = similitude[..., 0] / rotor_norm
    result[..., 1] = similitude[..., 1] / rotor_norm

    # Step 2: Enforce Similitude constraint (eie+ = eie-)
    avg_2 = (result[..., 2] + result[..., 3]) / 2
    result[..., 2] = avg_2
    result[..., 3] = avg_2
    avg_4 = (result[..., 4] + result[..., 5]) / 2
    result[..., 4] = avg_4
    result[..., 5] = avg_4

    return result


@torch.jit.script
def soft_structure_normalize(similitude: Tensor, strength: float = 1.0, eps: float = 1e-8) -> Tensor:
    """
    Soft structure normalization with interpolation.

    Args:
        similitude: Similitude tensor, shape (..., 8)
        strength: Interpolation strength (0=no change, 1=full normalize)
        eps: Numerical stability constant

    Returns:
        Soft-normalized Similitude, shape (..., 8)
    """
    normalized = structure_normalize(similitude, eps)
    return similitude + strength * (normalized - similitude)
