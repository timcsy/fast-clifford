"""
Clifford Algebra Cl(3, 0) Functional Operations - Auto-generated

DO NOT EDIT MANUALLY - This file is generated by codegen/generator.py

Generated: 2025-12-18 23:44:38
Signature: Cl(3, 0)
Blade count: 8
Rotor count: 4
Bivector count: 3
Algebra type: vga

All functions are:
- Loop-free (fully expanded arithmetic)
- ONNX-compatible (only Add/Mul/Neg/Sub operations)
- torch.jit.script compatible
"""

import torch
from torch import Tensor
from typing import Tuple


# =============================================================================
# Constants
# =============================================================================

BLADE_COUNT = 8
ROTOR_COUNT = 4
BIVECTOR_COUNT = 3

# Blade indices by grade
GRADE_0_INDICES = (0,)
GRADE_1_INDICES = (1, 2, 3)
GRADE_2_INDICES = (4, 5, 6)
GRADE_3_INDICES = (7,)

# Rotor (even-grade) indices
ROTOR_MASK = (0, 4, 5, 6)

# Bivector (grade-2) indices
BIVECTOR_MASK = (4, 5, 6)

# Vector (grade-1) indices
VECTOR_MASK = (1, 2, 3)

# Reverse signs for all blades
REVERSE_SIGNS = (1, 1, 1, 1, -1, -1, -1, -1)

# Involute signs for all blades
INVOLUTE_SIGNS = (1, -1, -1, -1, 1, 1, 1, -1)

# Conjugate signs for all blades
CONJUGATE_SIGNS = (1, -1, -1, -1, -1, -1, -1, 1)

# Inner product signs (blade² values)
INNER_PRODUCT_SIGNS = (1, 1, 1, 1, -1, -1, -1, -1)

# Pseudoscalar info
PSEUDOSCALAR_INDEX = 7
PSEUDOSCALAR_SQUARE = -1

# =============================================================================
# Geometric Product
# =============================================================================

@torch.jit.script
def geometric_product(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute geometric product of two multivectors in Cl(3, 0).

    Args:
        a: Left operand, shape (..., 8)
        b: Right operand, shape (..., 8)

    Returns:
        Result multivector, shape (..., 8)
    """
    r0 = (
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        -a[..., 7] * b[..., 7]
    )
    r1 = (
        a[..., 0] * b[..., 1] +
        a[..., 1] * b[..., 0] +
        -a[..., 2] * b[..., 4] +
        -a[..., 3] * b[..., 5] +
        a[..., 4] * b[..., 2] +
        a[..., 5] * b[..., 3] +
        -a[..., 6] * b[..., 7] +
        -a[..., 7] * b[..., 6]
    )
    r2 = (
        a[..., 0] * b[..., 2] +
        a[..., 1] * b[..., 4] +
        a[..., 2] * b[..., 0] +
        -a[..., 3] * b[..., 6] +
        -a[..., 4] * b[..., 1] +
        a[..., 5] * b[..., 7] +
        a[..., 6] * b[..., 3] +
        a[..., 7] * b[..., 5]
    )
    r3 = (
        a[..., 0] * b[..., 3] +
        a[..., 1] * b[..., 5] +
        a[..., 2] * b[..., 6] +
        a[..., 3] * b[..., 0] +
        -a[..., 4] * b[..., 7] +
        -a[..., 5] * b[..., 1] +
        -a[..., 6] * b[..., 2] +
        -a[..., 7] * b[..., 4]
    )
    r4 = (
        a[..., 0] * b[..., 4] +
        a[..., 1] * b[..., 2] +
        -a[..., 2] * b[..., 1] +
        a[..., 3] * b[..., 7] +
        a[..., 4] * b[..., 0] +
        -a[..., 5] * b[..., 6] +
        a[..., 6] * b[..., 5] +
        a[..., 7] * b[..., 3]
    )
    r5 = (
        a[..., 0] * b[..., 5] +
        a[..., 1] * b[..., 3] +
        -a[..., 2] * b[..., 7] +
        -a[..., 3] * b[..., 1] +
        a[..., 4] * b[..., 6] +
        a[..., 5] * b[..., 0] +
        -a[..., 6] * b[..., 4] +
        -a[..., 7] * b[..., 2]
    )
    r6 = (
        a[..., 0] * b[..., 6] +
        a[..., 1] * b[..., 7] +
        a[..., 2] * b[..., 3] +
        -a[..., 3] * b[..., 2] +
        -a[..., 4] * b[..., 5] +
        a[..., 5] * b[..., 4] +
        a[..., 6] * b[..., 0] +
        a[..., 7] * b[..., 1]
    )
    r7 = (
        a[..., 0] * b[..., 7] +
        a[..., 1] * b[..., 6] +
        -a[..., 2] * b[..., 5] +
        a[..., 3] * b[..., 4] +
        a[..., 4] * b[..., 3] +
        -a[..., 5] * b[..., 2] +
        a[..., 6] * b[..., 1] +
        a[..., 7] * b[..., 0]
    )

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Reverse Operation
# =============================================================================

@torch.jit.script
def reverse(mv: Tensor) -> Tensor:
    """
    Compute reverse of a multivector in Cl(3, 0).

    For grade k: coefficient *= (-1)^(k*(k-1)/2)

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Reversed multivector, shape (..., 8)
    """
    r0 = mv[..., 0]
    r1 = mv[..., 1]
    r2 = mv[..., 2]
    r3 = mv[..., 3]
    r4 = -mv[..., 4]
    r5 = -mv[..., 5]
    r6 = -mv[..., 6]
    r7 = -mv[..., 7]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Grade Involution
# =============================================================================

@torch.jit.script
def involute(mv: Tensor) -> Tensor:
    """
    Compute grade involution of a multivector in Cl(3, 0).

    For grade k: coefficient *= (-1)^k

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Grade-involuted multivector, shape (..., 8)
    """
    r0 = mv[..., 0]
    r1 = -mv[..., 1]
    r2 = -mv[..., 2]
    r3 = -mv[..., 3]
    r4 = mv[..., 4]
    r5 = mv[..., 5]
    r6 = mv[..., 6]
    r7 = -mv[..., 7]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Clifford Conjugate
# =============================================================================

@torch.jit.script
def conjugate(mv: Tensor) -> Tensor:
    """
    Compute Clifford conjugate of a multivector in Cl(3, 0).

    For grade k: coefficient *= (-1)^(k*(k+1)/2)

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Conjugated multivector, shape (..., 8)
    """
    r0 = mv[..., 0]
    r1 = -mv[..., 1]
    r2 = -mv[..., 2]
    r3 = -mv[..., 3]
    r4 = -mv[..., 4]
    r5 = -mv[..., 5]
    r6 = -mv[..., 6]
    r7 = mv[..., 7]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Grade Selection
# =============================================================================

@torch.jit.script
def select_grade_0(mv: Tensor) -> Tensor:
    """
    Extract grade-0 components from multivector.

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Multivector with only grade-0 components, shape (..., 8)
    """
    r0 = mv[..., 0]
    r1 = torch.zeros_like(mv[..., 1])
    r2 = torch.zeros_like(mv[..., 2])
    r3 = torch.zeros_like(mv[..., 3])
    r4 = torch.zeros_like(mv[..., 4])
    r5 = torch.zeros_like(mv[..., 5])
    r6 = torch.zeros_like(mv[..., 6])
    r7 = torch.zeros_like(mv[..., 7])

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)


@torch.jit.script
def select_grade_1(mv: Tensor) -> Tensor:
    """
    Extract grade-1 components from multivector.

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Multivector with only grade-1 components, shape (..., 8)
    """
    r0 = torch.zeros_like(mv[..., 0])
    r1 = mv[..., 1]
    r2 = mv[..., 2]
    r3 = mv[..., 3]
    r4 = torch.zeros_like(mv[..., 4])
    r5 = torch.zeros_like(mv[..., 5])
    r6 = torch.zeros_like(mv[..., 6])
    r7 = torch.zeros_like(mv[..., 7])

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)


@torch.jit.script
def select_grade_2(mv: Tensor) -> Tensor:
    """
    Extract grade-2 components from multivector.

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Multivector with only grade-2 components, shape (..., 8)
    """
    r0 = torch.zeros_like(mv[..., 0])
    r1 = torch.zeros_like(mv[..., 1])
    r2 = torch.zeros_like(mv[..., 2])
    r3 = torch.zeros_like(mv[..., 3])
    r4 = mv[..., 4]
    r5 = mv[..., 5]
    r6 = mv[..., 6]
    r7 = torch.zeros_like(mv[..., 7])

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)


@torch.jit.script
def select_grade_3(mv: Tensor) -> Tensor:
    """
    Extract grade-3 components from multivector.

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Multivector with only grade-3 components, shape (..., 8)
    """
    r0 = torch.zeros_like(mv[..., 0])
    r1 = torch.zeros_like(mv[..., 1])
    r2 = torch.zeros_like(mv[..., 2])
    r3 = torch.zeros_like(mv[..., 3])
    r4 = torch.zeros_like(mv[..., 4])
    r5 = torch.zeros_like(mv[..., 5])
    r6 = torch.zeros_like(mv[..., 6])
    r7 = mv[..., 7]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)


# =============================================================================
# Inner Product
# =============================================================================

@torch.jit.script
def inner(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute inner product <ab>_0 in Cl(3, 0).

    Args:
        a: Left operand, shape (..., 8)
        b: Right operand, shape (..., 8)

    Returns:
        Scalar result, shape (..., 1)
    """
    result = (
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        -a[..., 7] * b[..., 7]
    )
    return result.unsqueeze(-1)

# =============================================================================
# Outer Product (Wedge)
# =============================================================================

@torch.jit.script
def outer(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute outer product a ^ b in Cl(3, 0).

    Args:
        a: Left operand, shape (..., 8)
        b: Right operand, shape (..., 8)

    Returns:
        Result multivector, shape (..., 8)
    """
    r0 = a[..., 0] * b[..., 0]
    r1 = a[..., 0] * b[..., 1] + a[..., 1] * b[..., 0]
    r2 = a[..., 0] * b[..., 2] + a[..., 2] * b[..., 0]
    r3 = a[..., 0] * b[..., 3] + a[..., 3] * b[..., 0]
    r4 = (
        a[..., 0] * b[..., 4] +
        a[..., 1] * b[..., 2] +
        -a[..., 2] * b[..., 1] +
        a[..., 4] * b[..., 0]
    )
    r5 = (
        a[..., 0] * b[..., 5] +
        a[..., 1] * b[..., 3] +
        -a[..., 3] * b[..., 1] +
        a[..., 5] * b[..., 0]
    )
    r6 = (
        a[..., 0] * b[..., 6] +
        a[..., 2] * b[..., 3] +
        -a[..., 3] * b[..., 2] +
        a[..., 6] * b[..., 0]
    )
    r7 = (
        a[..., 0] * b[..., 7] +
        a[..., 1] * b[..., 6] +
        -a[..., 2] * b[..., 5] +
        a[..., 3] * b[..., 4] +
        a[..., 4] * b[..., 3] +
        -a[..., 5] * b[..., 2] +
        a[..., 6] * b[..., 1] +
        a[..., 7] * b[..., 0]
    )

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Left Contraction
# =============================================================================

@torch.jit.script
def contract_left(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute left contraction a << b in Cl(3, 0).

    Args:
        a: Left operand, shape (..., 8)
        b: Right operand, shape (..., 8)

    Returns:
        Result multivector, shape (..., 8)
    """
    r0 = (
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        -a[..., 7] * b[..., 7]
    )
    r1 = (
        a[..., 0] * b[..., 1] +
        -a[..., 2] * b[..., 4] +
        -a[..., 3] * b[..., 5] +
        -a[..., 6] * b[..., 7]
    )
    r2 = (
        a[..., 0] * b[..., 2] +
        a[..., 1] * b[..., 4] +
        -a[..., 3] * b[..., 6] +
        a[..., 5] * b[..., 7]
    )
    r3 = (
        a[..., 0] * b[..., 3] +
        a[..., 1] * b[..., 5] +
        a[..., 2] * b[..., 6] +
        -a[..., 4] * b[..., 7]
    )
    r4 = a[..., 0] * b[..., 4] + a[..., 3] * b[..., 7]
    r5 = a[..., 0] * b[..., 5] + -a[..., 2] * b[..., 7]
    r6 = a[..., 0] * b[..., 6] + a[..., 1] * b[..., 7]
    r7 = a[..., 0] * b[..., 7]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Right Contraction
# =============================================================================

@torch.jit.script
def contract_right(a: Tensor, b: Tensor) -> Tensor:
    """
    Compute right contraction a >> b in Cl(3, 0).

    Args:
        a: Left operand, shape (..., 8)
        b: Right operand, shape (..., 8)

    Returns:
        Result multivector, shape (..., 8)
    """
    r0 = (
        a[..., 0] * b[..., 0] +
        a[..., 1] * b[..., 1] +
        a[..., 2] * b[..., 2] +
        a[..., 3] * b[..., 3] +
        -a[..., 4] * b[..., 4] +
        -a[..., 5] * b[..., 5] +
        -a[..., 6] * b[..., 6] +
        -a[..., 7] * b[..., 7]
    )
    r1 = (
        a[..., 1] * b[..., 0] +
        a[..., 4] * b[..., 2] +
        a[..., 5] * b[..., 3] +
        -a[..., 7] * b[..., 6]
    )
    r2 = (
        a[..., 2] * b[..., 0] +
        -a[..., 4] * b[..., 1] +
        a[..., 6] * b[..., 3] +
        a[..., 7] * b[..., 5]
    )
    r3 = (
        a[..., 3] * b[..., 0] +
        -a[..., 5] * b[..., 1] +
        -a[..., 6] * b[..., 2] +
        -a[..., 7] * b[..., 4]
    )
    r4 = a[..., 4] * b[..., 0] + a[..., 7] * b[..., 3]
    r5 = a[..., 5] * b[..., 0] + -a[..., 7] * b[..., 2]
    r6 = a[..., 6] * b[..., 0] + a[..., 7] * b[..., 1]
    r7 = a[..., 7] * b[..., 0]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Dual (Left Contraction with Pseudoscalar)
# =============================================================================

@torch.jit.script
def dual(mv: Tensor) -> Tensor:
    """
    Compute dual mv* = mv << I in Cl(3, 0).

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Dual multivector, shape (..., 8)
    """
    r0 = -mv[..., 7]
    r1 = -mv[..., 6]
    r2 = mv[..., 5]
    r3 = -mv[..., 4]
    r4 = mv[..., 3]
    r5 = -mv[..., 2]
    r6 = mv[..., 1]
    r7 = mv[..., 0]

    return torch.stack([
        r0, r1, r2, r3, r4, r5, r6, r7,
    ], dim=-1)

# =============================================================================
# Norm Squared
# =============================================================================

@torch.jit.script
def norm_squared(mv: Tensor) -> Tensor:
    """
    Compute norm squared |mv|^2 = <mv * ~mv>_0 in Cl(3, 0).

    Args:
        mv: Input multivector, shape (..., 8)

    Returns:
        Norm squared, shape (..., 1)
    """
    result = (
        mv[..., 0] * mv[..., 0] +
        mv[..., 1] * mv[..., 1] +
        mv[..., 2] * mv[..., 2] +
        mv[..., 3] * mv[..., 3] +
        mv[..., 4] * mv[..., 4] +
        mv[..., 5] * mv[..., 5] +
        mv[..., 6] * mv[..., 6] +
        mv[..., 7] * mv[..., 7]
    )
    return result.unsqueeze(-1)

# =============================================================================
# Rotor Composition
# =============================================================================

@torch.jit.script
def compose_rotor(r1: Tensor, r2: Tensor) -> Tensor:
    """
    Compose two rotors r1 * r2 in Cl(3, 0).

    Args:
        r1: Left rotor, shape (..., 4)
        r2: Right rotor, shape (..., 4)

    Returns:
        Composed rotor, shape (..., 4)
    """
    out0 = (
        r1[..., 0] * r2[..., 0] +
        -r1[..., 1] * r2[..., 1] +
        -r1[..., 2] * r2[..., 2] +
        -r1[..., 3] * r2[..., 3]
    )
    out1 = (
        r1[..., 0] * r2[..., 1] +
        r1[..., 1] * r2[..., 0] +
        -r1[..., 2] * r2[..., 3] +
        r1[..., 3] * r2[..., 2]
    )
    out2 = (
        r1[..., 0] * r2[..., 2] +
        r1[..., 1] * r2[..., 3] +
        r1[..., 2] * r2[..., 0] +
        -r1[..., 3] * r2[..., 1]
    )
    out3 = (
        r1[..., 0] * r2[..., 3] +
        -r1[..., 1] * r2[..., 2] +
        r1[..., 2] * r2[..., 1] +
        r1[..., 3] * r2[..., 0]
    )

    return torch.stack([
        out0, out1, out2, out3,
    ], dim=-1)

# =============================================================================
# Rotor Reverse
# =============================================================================

@torch.jit.script
def reverse_rotor(r: Tensor) -> Tensor:
    """
    Compute reverse of a rotor in Cl(3, 0).

    Args:
        r: Input rotor, shape (..., 4)

    Returns:
        Reversed rotor, shape (..., 4)
    """
    r0 = r[..., 0]
    r1 = -r[..., 1]
    r2 = -r[..., 2]
    r3 = -r[..., 3]

    return torch.stack([
        r0, r1, r2, r3,
    ], dim=-1)

# =============================================================================
# Rotor Sandwich Product
# =============================================================================

@torch.jit.script
def sandwich_rotor(r: Tensor, x: Tensor) -> Tensor:
    """
    Compute sandwich product r * x * ~r in Cl(3, 0).

    Args:
        r: Rotor, shape (..., 4)
        x: Operand multivector, shape (..., 8)

    Returns:
        Transformed multivector, shape (..., 8)

    Note:
        This is a simplified implementation. Optimized sparse versions
        can be generated for specific input types (e.g., vectors).
    """
    # Expand rotor to full multivector
    rf0 = r[..., 0]
    rf1 = torch.zeros_like(r[..., 0])
    rf2 = torch.zeros_like(r[..., 0])
    rf3 = torch.zeros_like(r[..., 0])
    rf4 = r[..., 1]
    rf5 = r[..., 2]
    rf6 = r[..., 3]
    rf7 = torch.zeros_like(r[..., 0])

    # Compute r * x
    t0 = (
        rf0 * x[..., 0] +
        rf1 * x[..., 1] +
        rf2 * x[..., 2] +
        rf3 * x[..., 3] +
        -rf4 * x[..., 4] +
        -rf5 * x[..., 5] +
        -rf6 * x[..., 6] +
        -rf7 * x[..., 7]
    )
    t1 = (
        rf0 * x[..., 1] +
        rf1 * x[..., 0] +
        -rf2 * x[..., 4] +
        -rf3 * x[..., 5] +
        rf4 * x[..., 2] +
        rf5 * x[..., 3] +
        -rf6 * x[..., 7] +
        -rf7 * x[..., 6]
    )
    t2 = (
        rf0 * x[..., 2] +
        rf1 * x[..., 4] +
        rf2 * x[..., 0] +
        -rf3 * x[..., 6] +
        -rf4 * x[..., 1] +
        rf5 * x[..., 7] +
        rf6 * x[..., 3] +
        rf7 * x[..., 5]
    )
    t3 = (
        rf0 * x[..., 3] +
        rf1 * x[..., 5] +
        rf2 * x[..., 6] +
        rf3 * x[..., 0] +
        -rf4 * x[..., 7] +
        -rf5 * x[..., 1] +
        -rf6 * x[..., 2] +
        -rf7 * x[..., 4]
    )
    t4 = (
        rf0 * x[..., 4] +
        rf1 * x[..., 2] +
        -rf2 * x[..., 1] +
        rf3 * x[..., 7] +
        rf4 * x[..., 0] +
        -rf5 * x[..., 6] +
        rf6 * x[..., 5] +
        rf7 * x[..., 3]
    )
    t5 = (
        rf0 * x[..., 5] +
        rf1 * x[..., 3] +
        -rf2 * x[..., 7] +
        -rf3 * x[..., 1] +
        rf4 * x[..., 6] +
        rf5 * x[..., 0] +
        -rf6 * x[..., 4] +
        -rf7 * x[..., 2]
    )
    t6 = (
        rf0 * x[..., 6] +
        rf1 * x[..., 7] +
        rf2 * x[..., 3] +
        -rf3 * x[..., 2] +
        -rf4 * x[..., 5] +
        rf5 * x[..., 4] +
        rf6 * x[..., 0] +
        rf7 * x[..., 1]
    )
    t7 = (
        rf0 * x[..., 7] +
        rf1 * x[..., 6] +
        -rf2 * x[..., 5] +
        rf3 * x[..., 4] +
        rf4 * x[..., 3] +
        -rf5 * x[..., 2] +
        rf6 * x[..., 1] +
        rf7 * x[..., 0]
    )

    # Compute ~r
    rr0 = rf0
    rr1 = torch.zeros_like(r[..., 0])
    rr2 = torch.zeros_like(r[..., 0])
    rr3 = torch.zeros_like(r[..., 0])
    rr4 = -rf4
    rr5 = -rf5
    rr6 = -rf6
    rr7 = torch.zeros_like(r[..., 0])

    # Compute (r * x) * ~r
    s0 = (
        t0 * rr0 +
        t1 * rr1 +
        t2 * rr2 +
        t3 * rr3 +
        -t4 * rr4 +
        -t5 * rr5 +
        -t6 * rr6 +
        -t7 * rr7
    )
    s1 = (
        t0 * rr1 +
        t1 * rr0 +
        -t2 * rr4 +
        -t3 * rr5 +
        t4 * rr2 +
        t5 * rr3 +
        -t6 * rr7 +
        -t7 * rr6
    )
    s2 = (
        t0 * rr2 +
        t1 * rr4 +
        t2 * rr0 +
        -t3 * rr6 +
        -t4 * rr1 +
        t5 * rr7 +
        t6 * rr3 +
        t7 * rr5
    )
    s3 = (
        t0 * rr3 +
        t1 * rr5 +
        t2 * rr6 +
        t3 * rr0 +
        -t4 * rr7 +
        -t5 * rr1 +
        -t6 * rr2 +
        -t7 * rr4
    )
    s4 = (
        t0 * rr4 +
        t1 * rr2 +
        -t2 * rr1 +
        t3 * rr7 +
        t4 * rr0 +
        -t5 * rr6 +
        t6 * rr5 +
        t7 * rr3
    )
    s5 = (
        t0 * rr5 +
        t1 * rr3 +
        -t2 * rr7 +
        -t3 * rr1 +
        t4 * rr6 +
        t5 * rr0 +
        -t6 * rr4 +
        -t7 * rr2
    )
    s6 = (
        t0 * rr6 +
        t1 * rr7 +
        t2 * rr3 +
        -t3 * rr2 +
        -t4 * rr5 +
        t5 * rr4 +
        t6 * rr0 +
        t7 * rr1
    )
    s7 = (
        t0 * rr7 +
        t1 * rr6 +
        -t2 * rr5 +
        t3 * rr4 +
        t4 * rr3 +
        -t5 * rr2 +
        t6 * rr1 +
        t7 * rr0
    )

    return torch.stack([
        s0, s1, s2, s3, s4, s5, s6, s7,
    ], dim=-1)

# =============================================================================
# Rotor Norm Squared
# =============================================================================

@torch.jit.script
def norm_squared_rotor(r: Tensor) -> Tensor:
    """
    Compute norm squared of a rotor in Cl(3, 0).

    Args:
        r: Input rotor, shape (..., 4)

    Returns:
        Norm squared, shape (..., 1)
    """
    result = r[..., 0] * r[..., 0] + r[..., 1] * r[..., 1] + r[..., 2] * r[..., 2] + r[..., 3] * r[..., 3]
    return result.unsqueeze(-1)

# =============================================================================
# Bivector Exponential (exp_bivector)
# =============================================================================

@torch.jit.script
def exp_bivector(B: Tensor) -> Tensor:
    """
    Compute exponential of a bivector in Cl(3, 0).

    Converts a bivector (generator) to a rotor (rotation).
    Formula: exp(B) = cos(θ) + sin(θ)/θ * B where θ = sqrt(-B²)

    Args:
        B: Input bivector, shape (..., 3)

    Returns:
        Rotor, shape (..., 4)
    """
    B_sq = -B[..., 0] * B[..., 0] + -B[..., 1] * B[..., 1] + -B[..., 2] * B[..., 2]

    # θ² = -B² (bivectors square to negative in Euclidean)
    theta_sq = -B_sq

    # Handle both positive (elliptic) and negative (hyperbolic) cases
    # For numerical stability, use small angle approximation when θ ≈ 0
    eps = 1e-8

    # Elliptic case: θ² > 0 => exp(B) = cos(θ) + sin(θ)/θ * B
    # Hyperbolic case: θ² < 0 => exp(B) = cosh(θ) + sinh(θ)/θ * B
    theta = torch.sqrt(torch.abs(theta_sq) + eps)

    # Compute cos/cosh and sinc (sin(θ)/θ or sinh(θ)/θ)
    is_elliptic = theta_sq > 0
    cos_term = torch.where(is_elliptic, torch.cos(theta), torch.cosh(theta))
    sinc_term = torch.where(
        is_elliptic,
        torch.sin(theta) / theta,
        torch.sinh(theta) / theta
    )

    # Build rotor: scalar part + bivector parts
    r0 = cos_term
    r1 = sinc_term * B[..., 0]
    r2 = sinc_term * B[..., 1]
    r3 = sinc_term * B[..., 2]

    return torch.stack([
        r0, r1, r2, r3,
    ], dim=-1)

# =============================================================================
# Rotor Logarithm (log_rotor)
# =============================================================================

@torch.jit.script
def log_rotor(r: Tensor) -> Tensor:
    """
    Compute logarithm of a rotor in Cl(3, 0).

    Converts a rotor (rotation) to a bivector (generator).
    Formula: log(R) = atan2(|B|, s) / |B| * B where R = s + B

    Args:
        r: Input rotor, shape (..., 4)

    Returns:
        Bivector, shape (..., 3)
    """
    s = r[..., 0]  # Scalar part

    # Compute |B|² from bivector parts of rotor
    B_norm_sq = r[..., 1] * r[..., 1] + r[..., 2] * r[..., 2] + r[..., 3] * r[..., 3]

    # Compute angle θ = atan2(|B|, s)
    eps = 1e-8
    B_norm = torch.sqrt(B_norm_sq + eps)
    theta = torch.atan2(B_norm, s)

    # Scale factor: θ / |B|
    scale = theta / (B_norm + eps)

    # Extract bivector components from rotor
    b0 = scale * r[..., 1]
    b1 = scale * r[..., 2]
    b2 = scale * r[..., 3]

    return torch.stack([
        b0, b1, b2,
    ], dim=-1)

# =============================================================================
# Rotor SLERP (Spherical Linear Interpolation)
# =============================================================================

@torch.jit.script
def slerp_rotor(r1: Tensor, r2: Tensor, t: Tensor) -> Tensor:
    """
    Spherical linear interpolation between rotors in Cl(3, 0).

    Formula: slerp(r1, r2, t) = r1 * exp(t * log(r1~ * r2))

    Args:
        r1: Start rotor, shape (..., 4)
        r2: End rotor, shape (..., 4)
        t: Interpolation parameter [0, 1], shape (...) or scalar

    Returns:
        Interpolated rotor, shape (..., 4)
    """
    # Compute r1~ (reverse of r1)
    r1_rev = reverse_rotor(r1)

    # Compute delta = r1~ * r2
    delta = compose_rotor(r1_rev, r2)

    # Compute log of delta to get bivector
    log_delta = log_rotor(delta)

    # Scale by t
    if t.dim() == 0:
        scaled_log = t * log_delta
    else:
        scaled_log = t.unsqueeze(-1) * log_delta

    # Exponentiate back to rotor
    delta_t = exp_bivector(scaled_log)

    # Compose with r1
    return compose_rotor(r1, delta_t)
