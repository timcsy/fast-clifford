"""
Code generator for CGA Clifford algebra operations.

Generates hard-coded PyTorch functions with no loops,
fully expanded arithmetic for ONNX compatibility.
"""

from typing import Dict, List, Tuple, Optional
from datetime import datetime

from .base import AlgebraDefinition, CodeGenerator, SparsityPattern


class CGA3DAlgebra(AlgebraDefinition):
    """
    CGA Cl(4,1) algebra definition for code generation.

    Wraps the algebra.py module for use with the generator.
    """

    def __init__(self):
        # Import here to avoid circular imports
        from fast_clifford.algebras.cga3d import algebra

        self._algebra = algebra
        self._product_table = algebra.get_product_table()
        self._reverse_signs = algebra.REVERSE_SIGNS

    @property
    def name(self) -> str:
        return "cga3d"

    @property
    def signature(self) -> Tuple[int, ...]:
        return (1, 1, 1, 1, -1)

    @property
    def blade_count(self) -> int:
        return 32

    def get_grade_indices(self, grade: int) -> Tuple[int, ...]:
        return self._algebra.GRADE_INDICES[grade]

    def get_product_table(self) -> Dict[Tuple[int, int], Tuple[int, int]]:
        return self._product_table

    def get_reverse_signs(self) -> Tuple[int, ...]:
        return self._reverse_signs


class CGA3DCodeGenerator(CodeGenerator):
    """
    Code generator for CGA Cl(4,1) operations.

    Generates PyTorch code with:
    - Hard-coded arithmetic (no Cayley table lookups)
    - No loops (fully expanded)
    - ONNX-compatible operations only
    """

    def __init__(self, algebra: Optional[AlgebraDefinition] = None):
        if algebra is None:
            algebra = CGA3DAlgebra()
        super().__init__(algebra)

        # Cache product table organized by result index
        self._products_by_result = self._organize_products_by_result()

    def _organize_products_by_result(self) -> Dict[int, List[Tuple[int, int, int]]]:
        """
        Organize product rules by result index for efficient code generation.

        Returns:
            Dict mapping result_idx -> [(left_idx, right_idx, sign), ...]
        """
        result = {k: [] for k in range(self.algebra.blade_count)}
        for (left, right), (res, sign) in self.algebra.get_product_table().items():
            result[res].append((left, right, sign))
        return result

    def generate_header(self) -> str:
        """Generate module header with imports and docstring."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return f'''"""
CGA Cl(4,1) Functional Operations - Auto-generated

DO NOT EDIT MANUALLY - This file is generated by codegen/generate.py

Generated: {timestamp}
Algebra: {self.algebra.name}
Signature: {self.algebra.signature}
Blade count: {self.algebra.blade_count}

All functions are:
- Loop-free (fully expanded arithmetic)
- ONNX-compatible (only Add/Mul/Neg/Sub operations)
- Hard-coded (no Cayley table lookups)
"""

import torch
from torch import Tensor
from typing import Tuple

'''

    def generate_constants(self) -> str:
        """Generate constant definitions (T015)."""
        lines = [
            "# =============================================================================",
            "# Constants",
            "# =============================================================================",
            "",
            "BLADE_COUNT = 32",
            "",
            "# Blade indices by grade",
            f"GRADE_0_INDICES = {self.algebra.get_grade_indices(0)}",
            f"GRADE_1_INDICES = {self.algebra.get_grade_indices(1)}",
            f"GRADE_2_INDICES = {self.algebra.get_grade_indices(2)}",
            f"GRADE_3_INDICES = {self.algebra.get_grade_indices(3)}",
            f"GRADE_4_INDICES = {self.algebra.get_grade_indices(4)}",
            f"GRADE_5_INDICES = {self.algebra.get_grade_indices(5)}",
            "",
            "# Sparsity masks",
            "UPGC_POINT_MASK = GRADE_1_INDICES  # 5 components",
            "MOTOR_MASK = GRADE_0_INDICES + GRADE_2_INDICES + GRADE_4_INDICES  # 16 components",
            "",
            "# Reverse signs for all 32 blades",
            f"REVERSE_SIGNS = {self.algebra.get_reverse_signs()}",
            "",
            "# Motor-specific reverse signs (16 components)",
            "# Grade 0: +1, Grade 2: -1 (10 components), Grade 4: +1 (5 components)",
            "MOTOR_REVERSE_SIGNS = (1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1)",
            "",
        ]
        return "\n".join(lines)

    def generate_geometric_product(self) -> str:
        """Generate the full 32x32 geometric product function (T016)."""
        lines = [
            "# =============================================================================",
            "# Geometric Product (Full 32x32)",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def geometric_product_full(a: Tensor, b: Tensor) -> Tensor:",
            '    """',
            "    Compute the full geometric product of two multivectors.",
            "",
            "    Args:",
            "        a: Left operand, shape (..., 32)",
            "        b: Right operand, shape (..., 32)",
            "",
            "    Returns:",
            "        Result multivector, shape (..., 32)",
            "",
            "    Note:",
            "        Fully expanded, no loops, ONNX compatible.",
            '    """',
        ]

        # Generate computation for each result index
        for result_idx in range(self.algebra.blade_count):
            terms = self._products_by_result[result_idx]
            if not terms:
                lines.append(f"    # r{result_idx} = 0 (no contributions)")
                lines.append(f"    r{result_idx} = torch.zeros_like(a[..., 0])")
            else:
                # Build the sum of products
                term_strs = []
                for left, right, sign in terms:
                    if sign == 1:
                        term_strs.append(f"a[..., {left}] * b[..., {right}]")
                    else:
                        term_strs.append(f"-a[..., {left}] * b[..., {right}]")

                # Split into multiple lines if too many terms
                if len(term_strs) <= 3:
                    lines.append(f"    r{result_idx} = {' + '.join(term_strs)}")
                else:
                    lines.append(f"    r{result_idx} = (")
                    for i, term in enumerate(term_strs):
                        if i < len(term_strs) - 1:
                            lines.append(f"        {term} +")
                        else:
                            lines.append(f"        {term}")
                    lines.append("    )")

        # Stack all results
        lines.append("")
        lines.append("    return torch.stack([")
        for i in range(0, 32, 8):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + 8, 32)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_reverse(self) -> str:
        """Generate the reverse operation function (T017)."""
        signs = self.algebra.get_reverse_signs()

        lines = [
            "# =============================================================================",
            "# Reverse Operation",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def reverse_full(mv: Tensor) -> Tensor:",
            '    """',
            "    Compute the reverse of a multivector.",
            "",
            "    For grade k: coefficient *= (-1)^(k*(k-1)/2)",
            "    Grade 0, 1, 4, 5: sign = +1",
            "    Grade 2, 3: sign = -1",
            "",
            "    Args:",
            "        mv: Input multivector, shape (..., 32)",
            "",
            "    Returns:",
            "        Reversed multivector, shape (..., 32)",
            '    """',
        ]

        # Generate each component
        for idx in range(32):
            sign = signs[idx]
            if sign == 1:
                lines.append(f"    r{idx} = mv[..., {idx}]")
            else:
                lines.append(f"    r{idx} = -mv[..., {idx}]")

        # Stack results
        lines.append("")
        lines.append("    return torch.stack([")
        for i in range(0, 32, 8):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + 8, 32)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_sparse_section(self) -> str:
        """Generate sparse operation functions (T025, T026, T030)."""
        from .sparse_analysis import (
            get_sandwich_product_terms,
            MOTOR_FULL_INDICES,
            UPGC_POINT_FULL_INDICES,
            MOTOR_PATTERN,
            UPGC_POINT_PATTERN,
        )

        # Get all terms for sandwich product
        terms = get_sandwich_product_terms(
            self.algebra.get_product_table(),
            MOTOR_FULL_INDICES,
            UPGC_POINT_FULL_INDICES,
            self.algebra.get_reverse_signs()
        )

        lines = [
            "# =============================================================================",
            "# Sparse Operations (Motor x Point)",
            "# =============================================================================",
            "",
            "# Motor sparse indices: Grade 0 (1) + Grade 2 (10) + Grade 4 (5) = 16",
            "# Point sparse indices: Grade 1 (5)",
            "",
        ]

        # Generate upgc_encode (T026)
        lines.extend(self._generate_upgc_encode())
        lines.append("")

        # Generate upgc_decode (T026)
        lines.extend(self._generate_upgc_decode())
        lines.append("")

        # Generate reverse_motor (T030)
        lines.extend(self._generate_reverse_motor())
        lines.append("")

        # Generate sandwich_product_sparse (T025)
        lines.extend(self._generate_sandwich_product_sparse(terms))
        lines.append("")

        return "\n".join(lines)

    def _generate_upgc_encode(self) -> List[str]:
        """Generate UPGC encode function."""
        return [
            "@torch.jit.script",
            "def upgc_encode(x: Tensor) -> Tensor:",
            '    """',
            "    Encode 3D vector to UPGC point representation.",
            "",
            "    X = n_o + x + 0.5|x|^2 * n_inf",
            "",
            "    Where:",
            "        n_o = 0.5 * (e- - e+)   -> coefficients: e+ = -0.5, e- = 0.5",
            "        n_inf = e- + e+         -> coefficients: e+ = 1, e- = 1",
            "",
            "    Args:",
            "        x: 3D vector, shape (..., 3)",
            "",
            "    Returns:",
            "        UPGC point, shape (..., 5) as [e1, e2, e3, e+, e-]",
            '    """',
            "    x1 = x[..., 0]",
            "    x2 = x[..., 1]",
            "    x3 = x[..., 2]",
            "",
            "    # |x|^2 / 2",
            "    half_norm_sq = 0.5 * (x1 * x1 + x2 * x2 + x3 * x3)",
            "",
            "    # e1, e2, e3 components are just x",
            "    r0 = x1  # e1",
            "    r1 = x2  # e2",
            "    r2 = x3  # e3",
            "",
            "    # e+ component: -0.5 (from n_o) + half_norm_sq * 1 (from n_inf)",
            "    r3 = -0.5 + half_norm_sq  # e+",
            "",
            "    # e- component: 0.5 (from n_o) + half_norm_sq * 1 (from n_inf)",
            "    r4 = 0.5 + half_norm_sq  # e-",
            "",
            "    return torch.stack([r0, r1, r2, r3, r4], dim=-1)",
            "",
        ]

    def _generate_upgc_decode(self) -> List[str]:
        """Generate UPGC decode function."""
        return [
            "@torch.jit.script",
            "def upgc_decode(point: Tensor) -> Tensor:",
            '    """',
            "    Decode UPGC point to 3D vector.",
            "",
            "    Extracts the e1, e2, e3 components directly.",
            "",
            "    Args:",
            "        point: UPGC point, shape (..., 5) as [e1, e2, e3, e+, e-]",
            "",
            "    Returns:",
            "        3D vector, shape (..., 3)",
            '    """',
            "    return point[..., :3]",
            "",
        ]

    def _generate_reverse_motor(self) -> List[str]:
        """Generate reverse_motor function (T030)."""
        # Motor reverse signs: Grade 0 (+1), Grade 2 (-1 x 10), Grade 4 (+1 x 5)
        return [
            "@torch.jit.script",
            "def reverse_motor(motor: Tensor) -> Tensor:",
            '    """',
            "    Compute reverse of a motor (sparse 16-component version).",
            "",
            "    Motor layout (16 components):",
            "        [0]: scalar (Grade 0) -> +1",
            "        [1-10]: bivectors (Grade 2) -> -1",
            "        [11-15]: quadvectors (Grade 4) -> +1",
            "",
            "    Args:",
            "        motor: Motor, shape (..., 16)",
            "",
            "    Returns:",
            "        Reversed motor, shape (..., 16)",
            '    """',
            "    # Grade 0: keep sign",
            "    r0 = motor[..., 0]",
            "",
            "    # Grade 2 (10 components): negate",
            "    r1 = -motor[..., 1]",
            "    r2 = -motor[..., 2]",
            "    r3 = -motor[..., 3]",
            "    r4 = -motor[..., 4]",
            "    r5 = -motor[..., 5]",
            "    r6 = -motor[..., 6]",
            "    r7 = -motor[..., 7]",
            "    r8 = -motor[..., 8]",
            "    r9 = -motor[..., 9]",
            "    r10 = -motor[..., 10]",
            "",
            "    # Grade 4 (5 components): keep sign",
            "    r11 = motor[..., 11]",
            "    r12 = motor[..., 12]",
            "    r13 = motor[..., 13]",
            "    r14 = motor[..., 14]",
            "    r15 = motor[..., 15]",
            "",
            "    return torch.stack([",
            "        r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15",
            "    ], dim=-1)",
            "",
        ]

    def _generate_sandwich_product_sparse(
        self,
        terms: dict
    ) -> List[str]:
        """Generate sandwich_product_sparse function (T025)."""
        from .sparse_analysis import UPGC_POINT_FULL_INDICES, count_multiplication_ops

        lines = [
            "@torch.jit.script",
            "def sandwich_product_sparse(motor: Tensor, point: Tensor) -> Tensor:",
            '    """',
            "    Compute sparse sandwich product: M × X × M̃",
            "",
            "    Optimized for:",
            "        - Motor M: 16 components (Grade 0, 2, 4)",
            "        - Point X: 5 components (Grade 1)",
            "        - Output: 5 components (Grade 1)",
            "",
            "    Args:",
            "        motor: Motor, shape (..., 16)",
            "               [scalar, e12, e13, e1+, e1-, e23, e2+, e2-, e3+, e3-, e+-,",
            "                e123+, e123-, e12+-, e13+-, e23+-]",
            "        point: UPGC point, shape (..., 5)",
            "               [e1, e2, e3, e+, e-]",
            "",
            "    Returns:",
            "        Transformed point, shape (..., 5)",
            f"",
            f"    Note:",
            f"        Total multiplications: {count_multiplication_ops(terms)} (vs 2048 for full)",
            '    """',
            "    # Motor components (sparse)",
            "    m0 = motor[..., 0]    # scalar",
            "    m1 = motor[..., 1]    # e12",
            "    m2 = motor[..., 2]    # e13",
            "    m3 = motor[..., 3]    # e1+",
            "    m4 = motor[..., 4]    # e1-",
            "    m5 = motor[..., 5]    # e23",
            "    m6 = motor[..., 6]    # e2+",
            "    m7 = motor[..., 7]    # e2-",
            "    m8 = motor[..., 8]    # e3+",
            "    m9 = motor[..., 9]    # e3-",
            "    m10 = motor[..., 10]  # e+-",
            "    m11 = motor[..., 11]  # e123+",
            "    m12 = motor[..., 12]  # e123-",
            "    m13 = motor[..., 13]  # e12+-",
            "    m14 = motor[..., 14]  # e13+-",
            "    m15 = motor[..., 15]  # e23+-",
            "",
            "    # Point components (sparse)",
            "    p0 = point[..., 0]  # e1",
            "    p1 = point[..., 1]  # e2",
            "    p2 = point[..., 2]  # e3",
            "    p3 = point[..., 3]  # e+",
            "    p4 = point[..., 4]  # e-",
            "",
            "    # Motor reverse (Grade 2 negated)",
            "    mr0 = m0",
            "    mr1 = -m1",
            "    mr2 = -m2",
            "    mr3 = -m3",
            "    mr4 = -m4",
            "    mr5 = -m5",
            "    mr6 = -m6",
            "    mr7 = -m7",
            "    mr8 = -m8",
            "    mr9 = -m9",
            "    mr10 = -m10",
            "    mr11 = m11",
            "    mr12 = m12",
            "    mr13 = m13",
            "    mr14 = m14",
            "    mr15 = m15",
            "",
        ]

        # Generate output for each of the 5 point components
        for out_idx, full_idx in enumerate(UPGC_POINT_FULL_INDICES):
            component_terms = terms.get(full_idx, [])

            if not component_terms:
                lines.append(f"    # Output r{out_idx} (blade {full_idx}): no terms")
                lines.append(f"    r{out_idx} = torch.zeros_like(p0)")
            else:
                lines.append(f"    # Output r{out_idx} (blade {full_idx}): {len(component_terms)} terms")
                lines.append(f"    r{out_idx} = (")

                # Generate each term
                for i, (m_i, p_j, m_l, sign) in enumerate(component_terms):
                    sign_str = "" if sign == 1 else "-"
                    term = f"{sign_str}m{m_i} * p{p_j} * mr{m_l}"
                    if i < len(component_terms) - 1:
                        lines.append(f"        {term} +")
                    else:
                        lines.append(f"        {term}")
                lines.append("    )")
            lines.append("")

        # Return stacked result
        lines.append("    return torch.stack([r0, r1, r2, r3, r4], dim=-1)")
        lines.append("")

        return lines

    def generate_module(self) -> str:
        """Generate the complete functional.py module."""
        parts = [
            self.generate_header(),
            self.generate_constants(),
            self.generate_geometric_product(),
            self.generate_reverse(),
            self.generate_sparse_section(),
        ]
        return "\n".join(parts)


def generate_cga3d_functional(output_path: str) -> None:
    """
    Generate the CGA3D functional module.

    Args:
        output_path: Path to write the generated code
    """
    generator = CGA3DCodeGenerator()
    code = generator.generate_module()

    with open(output_path, 'w') as f:
        f.write(code)

    print(f"Generated: {output_path}")
    print(f"  - Constants: BLADE_COUNT, GRADE_*_INDICES, REVERSE_SIGNS")
    print(f"  - Functions: geometric_product_full, reverse_full")


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        generate_cga3d_functional(sys.argv[1])
    else:
        print("Usage: python -m fast_clifford.codegen.generate <output_path>")
