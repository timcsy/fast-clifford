"""
Code generator for CGA Clifford algebra operations.

Generates hard-coded PyTorch functions with no loops,
fully expanded arithmetic for ONNX compatibility.

Supports multiple CGA dimensions:
- CGA1D Cl(2,1): 8 blades
- CGA2D Cl(3,1): 16 blades
- CGA3D Cl(4,1): 32 blades
"""

from typing import Dict, List, Tuple, Optional
from datetime import datetime

from .base import AlgebraDefinition, CodeGenerator, SparsityPattern
from .cga_factory import (
    create_cga_algebra,
    compute_blade_count,
    compute_grade_indices,
    compute_reverse_signs,
    get_product_table,
    get_upgc_point_indices,
    get_motor_indices,
    get_blade_names,
)


class CGA3DAlgebra(AlgebraDefinition):
    """
    CGA Cl(4,1) algebra definition for code generation.

    Wraps the algebra.py module for use with the generator.
    """

    def __init__(self):
        # Import here to avoid circular imports
        from fast_clifford.algebras.cga3d import algebra

        self._algebra = algebra
        self._product_table = algebra.get_product_table()
        self._reverse_signs = algebra.REVERSE_SIGNS

    @property
    def name(self) -> str:
        return "cga3d"

    @property
    def signature(self) -> Tuple[int, ...]:
        return (1, 1, 1, 1, -1)

    @property
    def blade_count(self) -> int:
        return 32

    def get_grade_indices(self, grade: int) -> Tuple[int, ...]:
        return self._algebra.GRADE_INDICES[grade]

    def get_product_table(self) -> Dict[Tuple[int, int], Tuple[int, int]]:
        return self._product_table

    def get_reverse_signs(self) -> Tuple[int, ...]:
        return self._reverse_signs


class CGA3DCodeGenerator(CodeGenerator):
    """
    Code generator for CGA Cl(4,1) operations.

    Generates PyTorch code with:
    - Hard-coded arithmetic (no Cayley table lookups)
    - No loops (fully expanded)
    - ONNX-compatible operations only
    """

    def __init__(self, algebra: Optional[AlgebraDefinition] = None):
        if algebra is None:
            algebra = CGA3DAlgebra()
        super().__init__(algebra)

        # Cache product table organized by result index
        self._products_by_result = self._organize_products_by_result()

    def _organize_products_by_result(self) -> Dict[int, List[Tuple[int, int, int]]]:
        """
        Organize product rules by result index for efficient code generation.

        Returns:
            Dict mapping result_idx -> [(left_idx, right_idx, sign), ...]
        """
        result = {k: [] for k in range(self.algebra.blade_count)}
        for (left, right), (res, sign) in self.algebra.get_product_table().items():
            result[res].append((left, right, sign))
        return result

    def generate_header(self) -> str:
        """Generate module header with imports and docstring."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return f'''"""
CGA Cl(4,1) Functional Operations - Auto-generated

DO NOT EDIT MANUALLY - This file is generated by codegen/generate.py

Generated: {timestamp}
Algebra: {self.algebra.name}
Signature: {self.algebra.signature}
Blade count: {self.algebra.blade_count}

All functions are:
- Loop-free (fully expanded arithmetic)
- ONNX-compatible (only Add/Mul/Neg/Sub operations)
- Hard-coded (no Cayley table lookups)
"""

import torch
from torch import Tensor
from typing import Tuple

'''

    def generate_constants(self) -> str:
        """Generate constant definitions (T015)."""
        lines = [
            "# =============================================================================",
            "# Constants",
            "# =============================================================================",
            "",
            "BLADE_COUNT = 32",
            "",
            "# Blade indices by grade",
            f"GRADE_0_INDICES = {self.algebra.get_grade_indices(0)}",
            f"GRADE_1_INDICES = {self.algebra.get_grade_indices(1)}",
            f"GRADE_2_INDICES = {self.algebra.get_grade_indices(2)}",
            f"GRADE_3_INDICES = {self.algebra.get_grade_indices(3)}",
            f"GRADE_4_INDICES = {self.algebra.get_grade_indices(4)}",
            f"GRADE_5_INDICES = {self.algebra.get_grade_indices(5)}",
            "",
            "# Sparsity masks",
            "UPGC_POINT_MASK = GRADE_1_INDICES  # 5 components",
            "MOTOR_MASK = GRADE_0_INDICES + GRADE_2_INDICES + GRADE_4_INDICES  # 16 components",
            "",
            "# Reverse signs for all 32 blades",
            f"REVERSE_SIGNS = {self.algebra.get_reverse_signs()}",
            "",
            "# Motor-specific reverse signs (16 components)",
            "# Grade 0: +1, Grade 2: -1 (10 components), Grade 4: +1 (5 components)",
            "MOTOR_REVERSE_SIGNS = (1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1)",
            "",
        ]
        return "\n".join(lines)

    def generate_geometric_product(self) -> str:
        """Generate the full 32x32 geometric product function (T016)."""
        lines = [
            "# =============================================================================",
            "# Geometric Product (Full 32x32)",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def geometric_product_full(a: Tensor, b: Tensor) -> Tensor:",
            '    """',
            "    Compute the full geometric product of two multivectors.",
            "",
            "    Args:",
            "        a: Left operand, shape (..., 32)",
            "        b: Right operand, shape (..., 32)",
            "",
            "    Returns:",
            "        Result multivector, shape (..., 32)",
            "",
            "    Note:",
            "        Fully expanded, no loops, ONNX compatible.",
            '    """',
        ]

        # Generate computation for each result index
        for result_idx in range(self.algebra.blade_count):
            terms = self._products_by_result[result_idx]
            if not terms:
                lines.append(f"    # r{result_idx} = 0 (no contributions)")
                lines.append(f"    r{result_idx} = torch.zeros_like(a[..., 0])")
            else:
                # Build the sum of products
                term_strs = []
                for left, right, sign in terms:
                    if sign == 1:
                        term_strs.append(f"a[..., {left}] * b[..., {right}]")
                    else:
                        term_strs.append(f"-a[..., {left}] * b[..., {right}]")

                # Split into multiple lines if too many terms
                if len(term_strs) <= 3:
                    lines.append(f"    r{result_idx} = {' + '.join(term_strs)}")
                else:
                    lines.append(f"    r{result_idx} = (")
                    for i, term in enumerate(term_strs):
                        if i < len(term_strs) - 1:
                            lines.append(f"        {term} +")
                        else:
                            lines.append(f"        {term}")
                    lines.append("    )")

        # Stack all results
        lines.append("")
        lines.append("    return torch.stack([")
        for i in range(0, 32, 8):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + 8, 32)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_reverse(self) -> str:
        """Generate the reverse operation function (T017)."""
        signs = self.algebra.get_reverse_signs()

        lines = [
            "# =============================================================================",
            "# Reverse Operation",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def reverse_full(mv: Tensor) -> Tensor:",
            '    """',
            "    Compute the reverse of a multivector.",
            "",
            "    For grade k: coefficient *= (-1)^(k*(k-1)/2)",
            "    Grade 0, 1, 4, 5: sign = +1",
            "    Grade 2, 3: sign = -1",
            "",
            "    Args:",
            "        mv: Input multivector, shape (..., 32)",
            "",
            "    Returns:",
            "        Reversed multivector, shape (..., 32)",
            '    """',
        ]

        # Generate each component
        for idx in range(32):
            sign = signs[idx]
            if sign == 1:
                lines.append(f"    r{idx} = mv[..., {idx}]")
            else:
                lines.append(f"    r{idx} = -mv[..., {idx}]")

        # Stack results
        lines.append("")
        lines.append("    return torch.stack([")
        for i in range(0, 32, 8):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + 8, 32)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_sparse_section(self) -> str:
        """Generate sparse operation functions (T025, T026, T030)."""
        from .sparse_analysis import (
            get_sandwich_product_terms,
            MOTOR_FULL_INDICES,
            UPGC_POINT_FULL_INDICES,
            MOTOR_PATTERN,
            UPGC_POINT_PATTERN,
        )

        # Get all terms for sandwich product
        terms = get_sandwich_product_terms(
            self.algebra.get_product_table(),
            MOTOR_FULL_INDICES,
            UPGC_POINT_FULL_INDICES,
            self.algebra.get_reverse_signs()
        )

        lines = [
            "# =============================================================================",
            "# Sparse Operations (Motor x Point)",
            "# =============================================================================",
            "",
            "# Motor sparse indices: Grade 0 (1) + Grade 2 (10) + Grade 4 (5) = 16",
            "# Point sparse indices: Grade 1 (5)",
            "",
        ]

        # Generate upgc_encode (T026)
        lines.extend(self._generate_upgc_encode())
        lines.append("")

        # Generate upgc_decode (T026)
        lines.extend(self._generate_upgc_decode())
        lines.append("")

        # Generate reverse_motor (T030)
        lines.extend(self._generate_reverse_motor())
        lines.append("")

        # Generate sandwich_product_sparse (T025)
        lines.extend(self._generate_sandwich_product_sparse(terms))
        lines.append("")

        return "\n".join(lines)

    def _generate_upgc_encode(self) -> List[str]:
        """Generate UPGC encode function."""
        return [
            "@torch.jit.script",
            "def upgc_encode(x: Tensor) -> Tensor:",
            '    """',
            "    Encode 3D vector to UPGC point representation.",
            "",
            "    X = n_o + x + 0.5|x|^2 * n_inf",
            "",
            "    Where:",
            "        n_o = 0.5 * (e- - e+)   -> coefficients: e+ = -0.5, e- = 0.5",
            "        n_inf = e- + e+         -> coefficients: e+ = 1, e- = 1",
            "",
            "    Args:",
            "        x: 3D vector, shape (..., 3)",
            "",
            "    Returns:",
            "        UPGC point, shape (..., 5) as [e1, e2, e3, e+, e-]",
            '    """',
            "    x1 = x[..., 0]",
            "    x2 = x[..., 1]",
            "    x3 = x[..., 2]",
            "",
            "    # |x|^2 / 2",
            "    half_norm_sq = 0.5 * (x1 * x1 + x2 * x2 + x3 * x3)",
            "",
            "    # e1, e2, e3 components are just x",
            "    r0 = x1  # e1",
            "    r1 = x2  # e2",
            "    r2 = x3  # e3",
            "",
            "    # e+ component: -0.5 (from n_o) + half_norm_sq * 1 (from n_inf)",
            "    r3 = -0.5 + half_norm_sq  # e+",
            "",
            "    # e- component: 0.5 (from n_o) + half_norm_sq * 1 (from n_inf)",
            "    r4 = 0.5 + half_norm_sq  # e-",
            "",
            "    return torch.stack([r0, r1, r2, r3, r4], dim=-1)",
            "",
        ]

    def _generate_upgc_decode(self) -> List[str]:
        """Generate UPGC decode function."""
        return [
            "@torch.jit.script",
            "def upgc_decode(point: Tensor) -> Tensor:",
            '    """',
            "    Decode UPGC point to 3D vector.",
            "",
            "    Extracts the e1, e2, e3 components directly.",
            "",
            "    Args:",
            "        point: UPGC point, shape (..., 5) as [e1, e2, e3, e+, e-]",
            "",
            "    Returns:",
            "        3D vector, shape (..., 3)",
            '    """',
            "    return point[..., :3]",
            "",
        ]

    def _generate_reverse_motor(self) -> List[str]:
        """Generate reverse_motor function (T030)."""
        # Motor reverse signs: Grade 0 (+1), Grade 2 (-1 x 10), Grade 4 (+1 x 5)
        return [
            "@torch.jit.script",
            "def reverse_motor(motor: Tensor) -> Tensor:",
            '    """',
            "    Compute reverse of a motor (sparse 16-component version).",
            "",
            "    Motor layout (16 components):",
            "        [0]: scalar (Grade 0) -> +1",
            "        [1-10]: bivectors (Grade 2) -> -1",
            "        [11-15]: quadvectors (Grade 4) -> +1",
            "",
            "    Args:",
            "        motor: Motor, shape (..., 16)",
            "",
            "    Returns:",
            "        Reversed motor, shape (..., 16)",
            '    """',
            "    # Grade 0: keep sign",
            "    r0 = motor[..., 0]",
            "",
            "    # Grade 2 (10 components): negate",
            "    r1 = -motor[..., 1]",
            "    r2 = -motor[..., 2]",
            "    r3 = -motor[..., 3]",
            "    r4 = -motor[..., 4]",
            "    r5 = -motor[..., 5]",
            "    r6 = -motor[..., 6]",
            "    r7 = -motor[..., 7]",
            "    r8 = -motor[..., 8]",
            "    r9 = -motor[..., 9]",
            "    r10 = -motor[..., 10]",
            "",
            "    # Grade 4 (5 components): keep sign",
            "    r11 = motor[..., 11]",
            "    r12 = motor[..., 12]",
            "    r13 = motor[..., 13]",
            "    r14 = motor[..., 14]",
            "    r15 = motor[..., 15]",
            "",
            "    return torch.stack([",
            "        r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15",
            "    ], dim=-1)",
            "",
        ]

    def _generate_sandwich_product_sparse(
        self,
        terms: dict
    ) -> List[str]:
        """Generate sandwich_product_sparse function (T025)."""
        from .sparse_analysis import UPGC_POINT_FULL_INDICES, count_multiplication_ops

        lines = [
            "@torch.jit.script",
            "def sandwich_product_sparse(motor: Tensor, point: Tensor) -> Tensor:",
            '    """',
            "    Compute sparse sandwich product: M × X × M̃",
            "",
            "    Optimized for:",
            "        - Motor M: 16 components (Grade 0, 2, 4)",
            "        - Point X: 5 components (Grade 1)",
            "        - Output: 5 components (Grade 1)",
            "",
            "    Args:",
            "        motor: Motor, shape (..., 16)",
            "               [scalar, e12, e13, e1+, e1-, e23, e2+, e2-, e3+, e3-, e+-,",
            "                e123+, e123-, e12+-, e13+-, e23+-]",
            "        point: UPGC point, shape (..., 5)",
            "               [e1, e2, e3, e+, e-]",
            "",
            "    Returns:",
            "        Transformed point, shape (..., 5)",
            f"",
            f"    Note:",
            f"        Total multiplications: {count_multiplication_ops(terms)} (vs 2048 for full)",
            '    """',
            "    # Motor components (sparse)",
            "    m0 = motor[..., 0]    # scalar",
            "    m1 = motor[..., 1]    # e12",
            "    m2 = motor[..., 2]    # e13",
            "    m3 = motor[..., 3]    # e1+",
            "    m4 = motor[..., 4]    # e1-",
            "    m5 = motor[..., 5]    # e23",
            "    m6 = motor[..., 6]    # e2+",
            "    m7 = motor[..., 7]    # e2-",
            "    m8 = motor[..., 8]    # e3+",
            "    m9 = motor[..., 9]    # e3-",
            "    m10 = motor[..., 10]  # e+-",
            "    m11 = motor[..., 11]  # e123+",
            "    m12 = motor[..., 12]  # e123-",
            "    m13 = motor[..., 13]  # e12+-",
            "    m14 = motor[..., 14]  # e13+-",
            "    m15 = motor[..., 15]  # e23+-",
            "",
            "    # Point components (sparse)",
            "    p0 = point[..., 0]  # e1",
            "    p1 = point[..., 1]  # e2",
            "    p2 = point[..., 2]  # e3",
            "    p3 = point[..., 3]  # e+",
            "    p4 = point[..., 4]  # e-",
            "",
            "    # Motor reverse (Grade 2 negated)",
            "    mr0 = m0",
            "    mr1 = -m1",
            "    mr2 = -m2",
            "    mr3 = -m3",
            "    mr4 = -m4",
            "    mr5 = -m5",
            "    mr6 = -m6",
            "    mr7 = -m7",
            "    mr8 = -m8",
            "    mr9 = -m9",
            "    mr10 = -m10",
            "    mr11 = m11",
            "    mr12 = m12",
            "    mr13 = m13",
            "    mr14 = m14",
            "    mr15 = m15",
            "",
        ]

        # Generate output for each of the 5 point components
        for out_idx, full_idx in enumerate(UPGC_POINT_FULL_INDICES):
            component_terms = terms.get(full_idx, [])

            if not component_terms:
                lines.append(f"    # Output r{out_idx} (blade {full_idx}): no terms")
                lines.append(f"    r{out_idx} = torch.zeros_like(p0)")
            else:
                lines.append(f"    # Output r{out_idx} (blade {full_idx}): {len(component_terms)} terms")
                lines.append(f"    r{out_idx} = (")

                # Generate each term
                for i, (m_i, p_j, m_l, sign) in enumerate(component_terms):
                    sign_str = "" if sign == 1 else "-"
                    term = f"{sign_str}m{m_i} * p{p_j} * mr{m_l}"
                    if i < len(component_terms) - 1:
                        lines.append(f"        {term} +")
                    else:
                        lines.append(f"        {term}")
                lines.append("    )")
            lines.append("")

        # Return stacked result
        lines.append("    return torch.stack([r0, r1, r2, r3, r4], dim=-1)")
        lines.append("")

        return lines

    def generate_module(self) -> str:
        """Generate the complete functional.py module."""
        parts = [
            self.generate_header(),
            self.generate_constants(),
            self.generate_geometric_product(),
            self.generate_reverse(),
            self.generate_sparse_section(),
        ]
        return "\n".join(parts)


def generate_cga3d_functional(output_path: str) -> None:
    """
    Generate the CGA3D functional module.

    Args:
        output_path: Path to write the generated code
    """
    generator = CGA3DCodeGenerator()
    code = generator.generate_module()

    with open(output_path, 'w') as f:
        f.write(code)

    print(f"Generated: {output_path}")
    print(f"  - Constants: BLADE_COUNT, GRADE_*_INDICES, REVERSE_SIGNS")
    print(f"  - Functions: geometric_product_full, reverse_full")


class CGANDAlgebra(AlgebraDefinition):
    """
    通用化 CGA Cl(n+1,1) 代數定義。

    支援任意歐幾里得維度的 CGA 代數。
    """

    def __init__(self, euclidean_dim: int):
        """
        初始化 CGA 代數定義。

        Args:
            euclidean_dim: 歐幾里得空間維度 (1, 2, 或 3)
        """
        self._euclidean_dim = euclidean_dim
        self._blade_count = compute_blade_count(euclidean_dim)
        self._grade_indices = compute_grade_indices(euclidean_dim)
        self._product_table = get_product_table(euclidean_dim)
        self._reverse_signs = compute_reverse_signs(euclidean_dim)
        self._blade_names = get_blade_names(euclidean_dim)
        self._upgc_point_indices = get_upgc_point_indices(euclidean_dim)
        self._motor_indices = get_motor_indices(euclidean_dim)

    @property
    def euclidean_dim(self) -> int:
        return self._euclidean_dim

    @property
    def name(self) -> str:
        return f"cga{self._euclidean_dim}d"

    @property
    def signature(self) -> Tuple[int, ...]:
        # (+,...,+,-) 共 n+2 個元素
        return tuple([1] * (self._euclidean_dim + 1) + [-1])

    @property
    def blade_count(self) -> int:
        return self._blade_count

    def get_grade_indices(self, grade: int) -> Tuple[int, ...]:
        return self._grade_indices.get(grade, ())

    def get_product_table(self) -> Dict[Tuple[int, int], Tuple[int, int]]:
        return self._product_table

    def get_reverse_signs(self) -> Tuple[int, ...]:
        return self._reverse_signs

    def get_blade_names(self) -> List[str]:
        return self._blade_names

    def get_upgc_point_indices(self) -> Tuple[int, ...]:
        return self._upgc_point_indices

    def get_motor_indices(self) -> Tuple[int, ...]:
        return self._motor_indices


class CGANDCodeGenerator(CodeGenerator):
    """
    通用化 CGA Cl(n+1,1) 代碼生成器。

    生成 PyTorch 代碼，特性：
    - 硬編碼算術（無 Cayley 表查找）
    - 無循環（完全展開）
    - 僅 ONNX 相容操作
    """

    def __init__(self, euclidean_dim: int):
        """
        初始化代碼生成器。

        Args:
            euclidean_dim: 歐幾里得空間維度 (1, 2, 或 3)
        """
        algebra = CGANDAlgebra(euclidean_dim)
        super().__init__(algebra)
        self._euclidean_dim = euclidean_dim

        # 快取按結果索引組織的乘積規則
        self._products_by_result = self._organize_products_by_result()

    @property
    def euclidean_dim(self) -> int:
        return self._euclidean_dim

    def _organize_products_by_result(self) -> Dict[int, List[Tuple[int, int, int]]]:
        """
        按結果索引組織乘積規則。

        Returns:
            Dict 映射 result_idx -> [(left_idx, right_idx, sign), ...]
        """
        result = {k: [] for k in range(self.algebra.blade_count)}
        for (left, right), (res, sign) in self.algebra.get_product_table().items():
            result[res].append((left, right, sign))
        return result

    def generate_header(self) -> str:
        """生成模組標頭。"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        dim = self._euclidean_dim
        total_dim = dim + 2

        return f'''"""
CGA{dim}D Cl({dim+1},1) Functional Operations - Auto-generated

DO NOT EDIT MANUALLY - This file is generated by codegen/generate.py

Generated: {timestamp}
Algebra: {self.algebra.name}
Signature: {self.algebra.signature}
Blade count: {self.algebra.blade_count}

All functions are:
- Loop-free (fully expanded arithmetic)
- ONNX-compatible (only Add/Mul/Neg/Sub operations)
- Hard-coded (no Cayley table lookups)
"""

import torch
from torch import Tensor
from typing import Tuple

'''

    def generate_constants(self) -> str:
        """生成常數定義。"""
        dim = self._euclidean_dim
        total_dim = dim + 2
        blade_count = self.algebra.blade_count

        lines = [
            "# =============================================================================",
            "# Constants",
            "# =============================================================================",
            "",
            f"BLADE_COUNT = {blade_count}",
            f"EUCLIDEAN_DIM = {dim}",
            "",
            "# Blade indices by grade",
        ]

        # 生成各 grade 索引
        for grade in range(total_dim + 1):
            indices = self.algebra.get_grade_indices(grade)
            if indices:
                lines.append(f"GRADE_{grade}_INDICES = {indices}")

        lines.append("")
        lines.append("# Sparsity masks")

        # UPGC Point 遮罩
        upgc_indices = self.algebra.get_upgc_point_indices()
        lines.append(f"UPGC_POINT_MASK = {upgc_indices}  # {len(upgc_indices)} components")

        # Motor 遮罩
        motor_indices = self.algebra.get_motor_indices()
        lines.append(f"MOTOR_MASK = {motor_indices}  # {len(motor_indices)} components")

        lines.append("")
        lines.append(f"# Reverse signs for all {blade_count} blades")
        lines.append(f"REVERSE_SIGNS = {self.algebra.get_reverse_signs()}")

        # Motor reverse 符號
        lines.append("")
        lines.append(f"# Motor-specific reverse signs ({len(motor_indices)} components)")
        motor_reverse_signs = []
        for idx in motor_indices:
            motor_reverse_signs.append(self.algebra.get_reverse_signs()[idx])
        lines.append(f"MOTOR_REVERSE_SIGNS = {tuple(motor_reverse_signs)}")

        lines.append("")
        return "\n".join(lines)

    def generate_geometric_product(self) -> str:
        """生成完整幾何積函數。"""
        blade_count = self.algebra.blade_count

        lines = [
            "# =============================================================================",
            f"# Geometric Product (Full {blade_count}x{blade_count})",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def geometric_product_full(a: Tensor, b: Tensor) -> Tensor:",
            '    """',
            "    Compute the full geometric product of two multivectors.",
            "",
            "    Args:",
            f"        a: Left operand, shape (..., {blade_count})",
            f"        b: Right operand, shape (..., {blade_count})",
            "",
            "    Returns:",
            f"        Result multivector, shape (..., {blade_count})",
            "",
            "    Note:",
            "        Fully expanded, no loops, ONNX compatible.",
            '    """',
        ]

        # 為每個結果索引生成計算
        for result_idx in range(blade_count):
            terms = self._products_by_result[result_idx]
            if not terms:
                lines.append(f"    # r{result_idx} = 0 (no contributions)")
                lines.append(f"    r{result_idx} = torch.zeros_like(a[..., 0])")
            else:
                term_strs = []
                for left, right, sign in terms:
                    if sign == 1:
                        term_strs.append(f"a[..., {left}] * b[..., {right}]")
                    else:
                        term_strs.append(f"-a[..., {left}] * b[..., {right}]")

                if len(term_strs) <= 3:
                    lines.append(f"    r{result_idx} = {' + '.join(term_strs)}")
                else:
                    lines.append(f"    r{result_idx} = (")
                    for i, term in enumerate(term_strs):
                        if i < len(term_strs) - 1:
                            lines.append(f"        {term} +")
                        else:
                            lines.append(f"        {term}")
                    lines.append("    )")

        # Stack 所有結果
        lines.append("")
        lines.append("    return torch.stack([")

        # 按每 8 個分組
        chunk_size = 8
        for i in range(0, blade_count, chunk_size):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + chunk_size, blade_count)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_reverse(self) -> str:
        """生成 reverse 操作函數。"""
        signs = self.algebra.get_reverse_signs()
        blade_count = self.algebra.blade_count

        lines = [
            "# =============================================================================",
            "# Reverse Operation",
            "# =============================================================================",
            "",
            "@torch.jit.script",
            "def reverse_full(mv: Tensor) -> Tensor:",
            '    """',
            "    Compute the reverse of a multivector.",
            "",
            "    For grade k: coefficient *= (-1)^(k*(k-1)/2)",
            "",
            "    Args:",
            f"        mv: Input multivector, shape (..., {blade_count})",
            "",
            "    Returns:",
            f"        Reversed multivector, shape (..., {blade_count})",
            '    """',
        ]

        for idx in range(blade_count):
            sign = signs[idx]
            if sign == 1:
                lines.append(f"    r{idx} = mv[..., {idx}]")
            else:
                lines.append(f"    r{idx} = -mv[..., {idx}]")

        lines.append("")
        lines.append("    return torch.stack([")
        chunk_size = 8
        for i in range(0, blade_count, chunk_size):
            chunk = ", ".join(f"r{j}" for j in range(i, min(i + chunk_size, blade_count)))
            lines.append(f"        {chunk},")
        lines.append("    ], dim=-1)")
        lines.append("")

        return "\n".join(lines)

    def generate_sparse_section(self) -> str:
        """生成稀疏操作函數。"""
        from .sparse_analysis import (
            get_motor_pattern,
            get_upgc_point_pattern,
            get_sandwich_product_terms_generic,
            count_multiplication_ops,
        )

        dim = self._euclidean_dim
        motor_pattern = get_motor_pattern(dim)
        point_pattern = get_upgc_point_pattern(dim)
        terms = get_sandwich_product_terms_generic(dim)
        mul_ops = count_multiplication_ops(terms)

        motor_count = motor_pattern.sparse_count
        point_count = point_pattern.sparse_count
        motor_indices = motor_pattern.nonzero_indices
        point_indices = point_pattern.nonzero_indices

        # 取得 blade 名稱
        blade_names = self.algebra.get_blade_names()

        lines = [
            "# =============================================================================",
            f"# Sparse Operations (Motor[{motor_count}] x Point[{point_count}])",
            "# =============================================================================",
            "",
            f"# Motor sparse indices: {motor_indices}",
            f"# Point sparse indices: {point_indices}",
            "",
        ]

        # 生成 upgc_encode
        lines.extend(self._generate_upgc_encode(dim, point_indices, blade_names))
        lines.append("")

        # 生成 upgc_decode
        lines.extend(self._generate_upgc_decode(dim, point_count))
        lines.append("")

        # 生成 reverse_motor
        lines.extend(self._generate_reverse_motor(motor_pattern, blade_names))
        lines.append("")

        # 生成 sandwich_product_sparse
        lines.extend(self._generate_sandwich_product_sparse(
            terms, motor_pattern, point_pattern, blade_names, mul_ops
        ))
        lines.append("")

        return "\n".join(lines)

    def _generate_upgc_encode(
        self, dim: int, point_indices: Tuple[int, ...], blade_names: List[str]
    ) -> List[str]:
        """生成 UPGC encode 函數。"""
        point_count = len(point_indices)

        lines = [
            "@torch.jit.script",
            "def upgc_encode(x: Tensor) -> Tensor:",
            '    """',
            f"    Encode {dim}D vector to UPGC point representation.",
            "",
            "    X = n_o + x + 0.5|x|^2 * n_inf",
            "",
            "    Where:",
            "        n_o = 0.5 * (e- - e+)   -> coefficients: e+ = -0.5, e- = 0.5",
            "        n_inf = e- + e+         -> coefficients: e+ = 1, e- = 1",
            "",
            "    Args:",
            f"        x: {dim}D vector, shape (..., {dim})",
            "",
            "    Returns:",
            f"        UPGC point, shape (..., {point_count})",
            '    """',
        ]

        # 提取各分量
        for i in range(dim):
            lines.append(f"    x{i+1} = x[..., {i}]")
        lines.append("")

        # 計算 |x|^2 / 2
        norm_terms = " + ".join(f"x{i+1} * x{i+1}" for i in range(dim))
        lines.append(f"    half_norm_sq = 0.5 * ({norm_terms})")
        lines.append("")

        # 歐幾里得分量
        for i in range(dim):
            lines.append(f"    r{i} = x{i+1}  # {blade_names[point_indices[i]]}")

        # e+ 和 e- 分量
        # e+ = -0.5 + half_norm_sq
        # e- = 0.5 + half_norm_sq
        lines.append(f"    r{dim} = -0.5 + half_norm_sq  # e+")
        lines.append(f"    r{dim+1} = 0.5 + half_norm_sq  # e-")

        lines.append("")
        result_vars = ", ".join(f"r{i}" for i in range(point_count))
        lines.append(f"    return torch.stack([{result_vars}], dim=-1)")
        lines.append("")

        return lines

    def _generate_upgc_decode(self, dim: int, point_count: int) -> List[str]:
        """生成 UPGC decode 函數。"""
        return [
            "@torch.jit.script",
            "def upgc_decode(point: Tensor) -> Tensor:",
            '    """',
            f"    Decode UPGC point to {dim}D vector.",
            "",
            f"    Extracts the first {dim} components (euclidean part).",
            "",
            "    Args:",
            f"        point: UPGC point, shape (..., {point_count})",
            "",
            "    Returns:",
            f"        {dim}D vector, shape (..., {dim})",
            '    """',
            f"    return point[..., :{dim}]",
            "",
        ]

    def _generate_reverse_motor(
        self, motor_pattern: SparsityPattern, blade_names: List[str]
    ) -> List[str]:
        """生成 reverse_motor 函數。"""
        motor_count = motor_pattern.sparse_count
        motor_indices = motor_pattern.nonzero_indices
        reverse_signs = self.algebra.get_reverse_signs()

        lines = [
            "@torch.jit.script",
            "def reverse_motor(motor: Tensor) -> Tensor:",
            '    """',
            f"    Compute reverse of a motor (sparse {motor_count}-component version).",
            "",
            "    Args:",
            f"        motor: Motor, shape (..., {motor_count})",
            "",
            "    Returns:",
            f"        Reversed motor, shape (..., {motor_count})",
            '    """',
        ]

        # 對每個 motor 分量
        for sparse_idx, full_idx in enumerate(motor_indices):
            sign = reverse_signs[full_idx]
            name = blade_names[full_idx]
            if sign == 1:
                lines.append(f"    r{sparse_idx} = motor[..., {sparse_idx}]  # {name}: keep")
            else:
                lines.append(f"    r{sparse_idx} = -motor[..., {sparse_idx}]  # {name}: negate")

        lines.append("")
        result_vars = ", ".join(f"r{i}" for i in range(motor_count))
        lines.append(f"    return torch.stack([{result_vars}], dim=-1)")
        lines.append("")

        return lines

    def _generate_sandwich_product_sparse(
        self,
        terms: dict,
        motor_pattern: SparsityPattern,
        point_pattern: SparsityPattern,
        blade_names: List[str],
        mul_ops: int
    ) -> List[str]:
        """生成 sandwich_product_sparse 函數。"""
        motor_count = motor_pattern.sparse_count
        point_count = point_pattern.sparse_count
        motor_indices = motor_pattern.nonzero_indices
        point_indices = point_pattern.nonzero_indices
        reverse_signs = self.algebra.get_reverse_signs()

        # 計算理論最大乘法數
        full_ops = motor_count * point_count * motor_count * 2

        lines = [
            "@torch.jit.script",
            "def sandwich_product_sparse(motor: Tensor, point: Tensor) -> Tensor:",
            '    """',
            "    Compute sparse sandwich product: M × X × M̃",
            "",
            f"    Optimized for:",
            f"        - Motor M: {motor_count} components",
            f"        - Point X: {point_count} components",
            f"        - Output: {point_count} components",
            "",
            "    Args:",
            f"        motor: Motor, shape (..., {motor_count})",
            f"        point: UPGC point, shape (..., {point_count})",
            "",
            "    Returns:",
            f"        Transformed point, shape (..., {point_count})",
            "",
            f"    Note:",
            f"        Total multiplications: {mul_ops} (vs {full_ops} for naive)",
            '    """',
        ]

        # Motor 分量
        lines.append("    # Motor components (sparse)")
        for sparse_idx, full_idx in enumerate(motor_indices):
            name = blade_names[full_idx]
            lines.append(f"    m{sparse_idx} = motor[..., {sparse_idx}]  # {name}")
        lines.append("")

        # Point 分量
        lines.append("    # Point components (sparse)")
        for sparse_idx, full_idx in enumerate(point_indices):
            name = blade_names[full_idx]
            lines.append(f"    p{sparse_idx} = point[..., {sparse_idx}]  # {name}")
        lines.append("")

        # Motor reverse
        lines.append("    # Motor reverse")
        for sparse_idx, full_idx in enumerate(motor_indices):
            sign = reverse_signs[full_idx]
            if sign == 1:
                lines.append(f"    mr{sparse_idx} = m{sparse_idx}")
            else:
                lines.append(f"    mr{sparse_idx} = -m{sparse_idx}")
        lines.append("")

        # 對每個輸出分量生成計算
        for out_idx, full_idx in enumerate(point_indices):
            component_terms = terms.get(full_idx, [])

            if not component_terms:
                lines.append(f"    # Output r{out_idx} ({blade_names[full_idx]}): no terms")
                lines.append(f"    r{out_idx} = torch.zeros_like(p0)")
            else:
                lines.append(f"    # Output r{out_idx} ({blade_names[full_idx]}): {len(component_terms)} terms")
                lines.append(f"    r{out_idx} = (")

                for i, (m_i, p_j, m_l, sign) in enumerate(component_terms):
                    sign_str = "" if sign == 1 else "-"
                    term = f"{sign_str}m{m_i} * p{p_j} * mr{m_l}"
                    if i < len(component_terms) - 1:
                        lines.append(f"        {term} +")
                    else:
                        lines.append(f"        {term}")
                lines.append("    )")
            lines.append("")

        # 返回堆疊結果
        result_vars = ", ".join(f"r{i}" for i in range(point_count))
        lines.append(f"    return torch.stack([{result_vars}], dim=-1)")
        lines.append("")

        return lines

    def generate_module(self) -> str:
        """生成完整的 functional.py 模組。"""
        parts = [
            self.generate_header(),
            self.generate_constants(),
            self.generate_geometric_product(),
            self.generate_reverse(),
            self.generate_sparse_section(),
        ]
        return "\n".join(parts)


def generate_cgand_functional(euclidean_dim: int, output_path: str) -> None:
    """
    生成指定維度的 CGA functional 模組。

    Args:
        euclidean_dim: 歐幾里得空間維度 (1, 2, 或 3)
        output_path: 輸出檔案路徑
    """
    generator = CGANDCodeGenerator(euclidean_dim)
    code = generator.generate_module()

    with open(output_path, 'w') as f:
        f.write(code)

    print(f"Generated: {output_path}")
    print(f"  - Algebra: CGA{euclidean_dim}D Cl({euclidean_dim+1},1)")
    print(f"  - Blade count: {generator.algebra.blade_count}")
    print(f"  - Motor components: {len(generator.algebra.get_motor_indices())}")
    print(f"  - Point components: {len(generator.algebra.get_upgc_point_indices())}")


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 2:
        dim = int(sys.argv[1])
        output_path = sys.argv[2]
        generate_cgand_functional(dim, output_path)
    elif len(sys.argv) > 1:
        generate_cga3d_functional(sys.argv[1])
    else:
        print("Usage:")
        print("  python -m fast_clifford.codegen.generate <dim> <output_path>")
        print("  python -m fast_clifford.codegen.generate <output_path>  # CGA3D only")
