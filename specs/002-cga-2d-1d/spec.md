# 功能規格：CGA2D 與 CGA1D 支援

**功能分支**: `002-cga-2d-1d`
**建立日期**: 2025-12-07
**狀態**: 草稿
**輸入**: 使用者描述：「新增 CGA2D Cl(3,1) 和 CGA1D Cl(2,1) 支援，用於 2D 和 1D 共形幾何代數運算，針對 CARE Transformer 優化」

## 使用者情境與測試 *(必填)*

### 使用者故事 1 - 2D 幾何變換 (優先級: P1)

作為開發 2D CARE Transformer 模型的深度學習研究人員，我需要使用馬達（motor）和三明治積（sandwich product）對批次 2D 點執行高效的 2D 共形幾何代數運算（旋轉、平移、縮放）。

**為何此優先級**: CGA2D 是 CGA3D 之後最常需要的維度，支援 2D 影像/視覺應用和神經網路中的 2D 空間變換。

**獨立測試**: 可透過將 2D 點編碼為 UPGC 表示、透過三明治積套用馬達變換、然後解碼回 2D 座標來完整測試。可與 clifford 函式庫比對驗證結果。

**驗收場景**:

1. **假設** 有一批 2D 點和旋轉馬達，**當** 我套用三明治積，**則** 點在 2D 平面上被正確旋轉，數值誤差 < 1e-6
2. **假設** 有一批 2D 點和平移馬達，**當** 我套用三明治積，**則** 點被正確平移，數值誤差 < 1e-6
3. **假設** CGA2D 運算，**當** 我匯出至 ONNX，**則** 計算圖不包含 Loop 節點，且僅使用基本算子（Add、Mul、Neg）

---

### 使用者故事 2 - 1D 幾何變換 (優先級: P2)

作為開發用於時間序列或序列資料的 1D CARE Transformer 模型的深度學習研究人員，我需要對批次 1D 點執行高效的 1D 共形幾何代數運算（平移、縮放）。

**為何此優先級**: CGA1D 可實現 1D 空間變換，適用於時間序列、音訊處理和 Transformer 中的序列注意力機制。

**獨立測試**: 可透過將 1D 純量編碼為 UPGC 表示、套用馬達變換、然後解碼回來完整測試。可與 clifford 函式庫比對驗證。

**驗收場景**:

1. **假設** 有一批 1D 純量和平移馬達，**當** 我套用三明治積，**則** 純量被正確平移，數值誤差 < 1e-6
2. **假設** CGA1D 運算，**當** 我匯出至 ONNX，**則** 計算圖不包含 Loop 節點

---

### 使用者故事 3 - PyTorch 訓練整合 (優先級: P1)

作為機器學習工程師，我需要 CGA2D 和 CGA1D 層能無縫整合到 PyTorch 訓練流程中，支援自動微分、批次處理和混合精度（fp16/fp32）。

**為何此優先級**: 這對深度學習的實際應用至關重要——沒有 PyTorch 整合，這些運算就無法用於模型訓練。

**獨立測試**: 可透過建立使用 CGA 層的簡單神經網路、執行前向/反向傳播、並驗證梯度流動來測試。

**驗收場景**:

1. **假設** CGA2DCareLayer 和 CGA1DCareLayer 模組，**當** 在 PyTorch 模型中使用，**則** 梯度正確地通過這些層傳播
2. **假設** fp16 輸入張量，**當** 由 CGA 層處理，**則** 內部計算使用 fp32 且輸出保持 fp16 dtype
3. **假設** 批次輸入，**當** 由 CGA 層處理，**則** 批次維度被正確處理並進行平行計算

---

### 邊界案例

- 當馬達未正規化時會發生什麼？（應仍產生有效變換，可能影響縮放比例）
- 當輸入為零值時會發生什麼？（應優雅處理，回傳有效的零點）
- 當座標值非常大時會發生什麼？（應透過 fp32 內部計算維持數值穩定性）
- 當批次大小為 1 時會發生什麼？（應與較大批次運作相同）

## 需求 *(必填)*

### 功能需求

**CGA2D Cl(3,1) 需求**:

- **FR-001**: 系統必須實作具有 16 個 blade（2^4）的 CGA2D 代數
- **FR-002**: 系統必須提供具有 4 個分量（e1、e2、e+、e-）的 UPGC 2D 點編碼
- **FR-003**: 系統必須提供具有 8 個分量（Grade 0、2、4）的 2D 馬達表示
- **FR-004**: 系統必須實作 CGA2D 的稀疏三明治積（Motor × Point × Motor̃）
- **FR-005**: 系統必須提供無迴圈的硬編碼幾何積（16×16）

**CGA1D Cl(2,1) 需求**:

- **FR-006**: 系統必須實作具有 8 個 blade（2^3）的 CGA1D 代數
- **FR-007**: 系統必須提供具有 3 個分量（e1、e+、e-）的 UPGC 1D 點編碼
- **FR-008**: 系統必須提供具有 4 個分量（Grade 0、2）的 1D 馬達表示
- **FR-009**: 系統必須實作 CGA1D 的稀疏三明治積
- **FR-010**: 系統必須提供無迴圈的硬編碼幾何積（8×8）

**共通需求**:

- **FR-011**: 系統必須在所有運算上支援 PyTorch 批次處理
- **FR-012**: 系統必須支援 opset 17 的 ONNX 匯出
- **FR-013**: 系統必須支援 CPU、CUDA 和 MPS（Apple Silicon）裝置
- **FR-014**: 系統必須處理混合精度（fp16 輸入搭配 fp32 內部計算）
- **FR-015**: 系統必須對所有生成的函式套用 torch.jit.script 優化
- **FR-016**: 系統必須驗證零基性質（eo²=0、einf²=0、eo·einf=-1）

### 關鍵實體

- **CGA2D 代數 Cl(3,1)**: 4 維空間，簽名（+,+,+,-），16 個 blade，用於 2D 共形變換
- **CGA1D 代數 Cl(2,1)**: 3 維空間，簽名（+,+,-），8 個 blade，用於 1D 共形變換
- **UPGC 點**: 共形空間中的上投影點，將歐幾里得點與額外的零基分量一起編碼
- **馬達（Motor）**: 編碼旋轉和平移的幾何代數元素，在三明治積中用於變換
- **三明治積**: M × X × M̃ 運算，使用馬達 M 變換點 X

## 成功標準 *(必填)*

### 可衡量的成果

- **SC-001**: CGA2D 三明治積使用少於 250 次乘法（相較於完整計算的 512 次），達成 >50% 減少
- **SC-002**: CGA1D 三明治積使用少於 80 次乘法（相較於完整計算的 128 次），達成 >50% 減少
- **SC-003**: 所有數值運算與 clifford 函式庫參考在 1e-6 容差內相符
- **SC-004**: ONNX 匯出的模型包含零個 Loop/If/Scan 節點
- **SC-005**: CGA2D 和 CGA1D 的批次處理吞吐量在 CPU 上超過每秒 100,000 點
- **SC-006**: 所有測試案例通過（幾何積、零基、結合律、反轉、三明治積、邊界案例）
- **SC-007**: CGA2D 和 CGA1D 模組可直接匯入並用於 PyTorch 訓練程式碼

## 假設

- 使用者熟悉共形幾何代數概念
- 主要使用場景為 CARE Transformer 和類似的幾何深度學習模型
- 效能需求與 CGA3D 實作模式一致
- clifford 函式庫作為數值正確性的參考實作
- 馬達正規化是使用者的責任（函式庫不自動正規化）
